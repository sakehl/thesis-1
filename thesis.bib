%% Created using Papers on Fri, 12 Jul 2013.
%% http://papersapp.com/papers/

@book{Altenkirch:2003kz,
author = {Altenkirch, Thorsten and Reus, Bernhard},
editor = {Flum, J{\"o}rg and Rodriguez-Artalejo, Mario},
title = {{Monadic Presentation of Lambda Terms Using Generalised Inductive Types}},
publisher = {Springer Berlin Heidelberg},
year = {2003},
volume = {1683},
series = {Lecture Notes in Computer Science},
address = {Berlin, Heidelberg},
edition = {Springer Berlin Heidelberg},
month = may
}

@inproceedings{Chakravarty:2011fr,
author = {Chakravarty, Manuel M T and Keller, Gabriele and Lee, Sean and McDonell, Trevor L. and Grover, Vinod},
title = {{Accelerating Haskell array codes with multicore GPUs}},
booktitle = {DAMP '11: Proceedings of the sixth workshop on Declarative aspects of multicore programming},
year = {2011},
publisher = { ACM  Request Permissions},
month = jan
}

@inproceedings{Palka:2011,
author = {Pa lka, Micha\l H. and Claessen, Koen and Russo, Alejandro and Hughes, John},
title = {{Testing an optimising compiler by generating random lambda terms}},
booktitle = {Proceedings of the 6th International Workshop on Automation of Software Test},
year = {2011},
pages = {91--97},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{Cole:2004,
author = {Cole, Murray},
title = {{Bringing skeletons out of the closet: a pragmatic manifesto for skeletal parallel programming}},
journal = {Parallel Computing},
year = {2004},
volume = {30},
number = {3},
pages = {389--406}
}

@article{Burstall:1977kl,
author = {Burstall, R M and Darlington, John},
title = {{A Transformation System for Developing Recursive Programs}},
journal = {Journal of the ACM (JACM},
year = {1977},
volume = {24},
number = {1},
month = jan
}

@inproceedings{Wadler:1984ia,
author = {Wadler, Philip},
title = {{Listlessness is better than laziness: Lazy evaluation and garbage collection at compile-time}},
booktitle = {LFP '84: Proceedings of the 1984 ACM Symposium on LISP and functional programming},
year = {1984},
publisher = { ACM  Request Permissions},
month = aug
}

@inproceedings{Darlington:1995,
author = {Darlington, John and Guo, Yi-ke and To, Hing Wing and Yang, Jin},
title = {{Parallel skeletons for structured composition}},
booktitle = {Proceedings of the fifth ACM SIGPLAN symposium on Principles and practice of parallel programming},
year = {1995},
pages = {19--28},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Pilkiewicz:2011,
author = {Pilkiewicz, Alexandre and Pottier, Fran{\c c}ois},
title = {{The Essence of Monotonic State}},
booktitle = {TLDI `11: Proceedings of the Sixth ACM SIGPLAN Workshop on Types in Language Design and Implementation},
year = {2011},
month = jan
}

@phdthesis{Gill:1996tf,
author = {Gill, Andrew},
title = {{Cheap Deforestation for Non-strict Functional Languages}},
school = {Department of Computer Science, University of Glasgow},
year = {1996}
}

@inproceedings{Darlington:2002,
author = {Darlington, John and Ghanem, M. and To, Hing Wing},
title = {{Structured parallel programming}},
booktitle = {Programming Models for Massively Parallel Computers},
year = {1993},
pages = {160--169},
organization = {IEEE}
}

@inproceedings{Jones:1989,
author = {Jones, Simon L. Peyton and Salkild, Jon},
title = {{The spineless tagless G-machine}},
booktitle = {Proceedings of the fourth international conference on Functional programming languages and computer architecture},
year = {1989},
pages = {184--201},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Wadler:1981hy,
author = {Wadler, Philip},
title = {{Applicative style programming, program transformation, and list operators}},
booktitle = {FPCA '81: Proceedings of the 1981 conference on Functional programming languages and computer architecture},
year = {1981},
publisher = { ACM  Request Permissions},
month = oct
}

@article{Landin:1966,
author = {Landin, P. J.},
title = {{The next 700 programming languages}},
journal = {Communications of the ACM},
year = {1966},
volume = {9},
pages = {157--166},
month = mar
}

@article{Chafi:2010up,
author = {Chafi, Hassan and DeVito, Zach and Moors, Adriaan and Rompf, Tiark and Sujeeth, Arvind K and Hanrahan, Pat and Odersky, Martin and Olukotun, Kunle},
title = {{Language virtualization for heterogeneous parallel computing}},
year = {2010},
volume = {45},
number = {10},
pages = {835--847}
}

@article{ThrustAParallelT:ub,
author = {Hoberock, Jared and Bell, Nathan},
title = {{Thrust: A Parallel Template Library}}
}

@inproceedings{Atkey:2009dj,
author = {Atkey, Robert and Lindley, Sam and Yallop, Jeremy},
title = {{Unembedding domain-specific languages}},
booktitle = {Proceedings of the 2nd ACM SIGPLAN symposium on Haskell},
year = {2009},
pages = {37--48},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{McBride:2006up,
author = {McBride, Conor},
title = {{Type-Preserving Renaming and Substitution}},
journal = {Journal of Functional Programming},
year = {2006}
}

@inproceedings{Guillemette:2007,
author = {Guillemette, Louis-Julien and Monnier, Stefan},
title = {{A type-preserving closure conversion in Haskell}},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell workshop},
year = {2007},
pages = {83--92},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Gill:1993de,
author = {Gill, Andrew and Launchbury, John and Peyton Jones, Simon L.},
title = {{A short cut to deforestation}},
booktitle = {Proceedings of the conference on Functional programming languages and computer architecture},
year = {1993},
pages = {223--232},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{AccelerEyes:vq,
author = {Melonakos, John and Malcolm, James},
title = {{AccelerEyes}}
}

@phdthesis{Bratvold:1994,
author = {Bratvold, Tore Andreas},
title = {{Skeleton-based parallelisation of functional programs}},
school = {Heriot-Watt University},
year = {1994},
month = nov
}

@inproceedings{Larsen:2011fa,
author = {Larsen, Bradford},
title = {{Simple Optimizations for an Applicative Array Language for Graphics Processors}},
booktitle = {DAMP `11: Proceedings of the 6th ACM SIGPLAN workshop on Declarative Aspects of Multicore Programming},
year = {2011},
month = jan
}

@inproceedings{Bergstrom:2012bi,
author = {Bergstrom, Lars and Reppy, John},
title = {{Nested data-parallelism on the GPU}},
booktitle = {ICFP '12: Proceedings of the 17th ACM SIGPLAN international conference on Functional programming},
year = {2012},
publisher = { ACM  Request Permissions},
month = sep
}

@article{Pfenning:1988,
author = {Pfenning, F. and Elliot, C.},
title = {{Higher-order abstract syntax}},
journal = {SIGPLAN Notices},
year = {1988},
volume = {23},
pages = {199--208},
month = jun
}

@inproceedings{Claessen:2000,
author = {Claessen, Koen and Hughes, John},
title = {{QuickCheck: a lightweight tool for random testing of Haskell programs}},
booktitle = {Proceedings of the fifth ACM SIGPLAN international conference on Functional programming},
year = {2000},
pages = {268--279},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Skillicorn:1993,
author = {Skillicorn, D. B.},
title = {{Structuring data parallelism using categorical data types}},
booktitle = {Programming Models for Massively Parallel Computers},
year = {1993},
pages = {110--115}
}

@phdthesis{To:1995,
author = {To, Hing Wing},
title = {{Optimising the Parallel Behaviour of Combinations of Program Components}},
school = {University of London, Imperial College of Science, Technology and Medicine},
year = {1995}
}

@inproceedings{Keller:2010er,
author = {Keller, Gabriele and Chakravarty, Manuel M T and Leshchinskiy, Roman and Peyton Jones, Simon and Lippmeier, Ben},
title = {{Regular, shape-polymorphic, parallel arrays in Haskell}},
booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming},
year = {2010},
pages = {261--272},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{Appel:1997gs,
author = {Appel, Andrew W and Jim, Trevor},
title = {{Shrinking lambda expressions in linear time}},
journal = {Journal of Functional Programming},
year = {1997},
volume = {7},
number = {5},
month = sep
}

@inproceedings{Onoue:1997,
author = {Onoue, Y. and Hu, Z. and Takeichi, M. and Iwasaki, H.},
title = {{A calculational fusion system HYLO}},
booktitle = {Proceedings of the IFIP TC 2 WG 2.1 international workshop on Algorithmic languages and calculi},
year = {1997},
pages = {76--106},
publisher = {Chapman \{\&} Hall, Ltd.},
address = {London, UK, UK}
}

@inproceedings{Skillcorn:1994,
author = {Skillicorn, D. B. and Cai, Wentong},
title = {{Equational code generation: implementing categorical data types for data parallelism}},
booktitle = {TENCON `94: Proceedings of the 9th IEEE conference on the Frontiers of Computer Technology},
year = {1994},
pages = {187--191}
}

@inproceedings{Pang:2004bg,
author = {Pang, Andr{\'e} and Stewart, Don and Seefried, Sean and Chakravarty, Manuel M T},
title = {{Plugging Haskell In}},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell},
year = {2004},
pages = {10--21},
publisher = {ACM Press}
}

@article{Kennedy:1993tw,
author = {Kennedy, Ken and McKinley, Kathryn S},
title = {{Typed fusion with applications to parallel and sequential code generation}},
journal = {userweb.cs.utexas.edu},
year = {1993}
}

@inproceedings{Chlipala:cn,
author = {Chlipala, Adam},
title = {{Parametric higher-order abstract syntax for mechanized semantics}},
booktitle = {ICFP '08: Proceeding of the 13th ACM SIGPLAN international conference on Functional programming},
year = {2008},
pages = {143--156},
publisher = { ACM  Request Permissions},
month = sep
}

@book{Muchnick:1997wv,
author = {Muchnick, Steven S},
title = {{Advanced compiler design and implementation}},
publisher = {Morgan Kaufmann},
year = {1997}
}

@proceedings{ParallelandConcurre:2012wo,
title = {{ï¿¼Parallel {\&} Concurrent Haskell 4: Software Transactional Memory}},
year = {2012},
month = jun
}

@proceedings{Marlow:2012wn,
title = {{ï¿¼Parallel {\&} Concurrent Haskell 1: Basic Pure Parallelism}},
year = {2012},
month = jun
}

@proceedings{ParallelandConcurre:2012ux,
title = {{ï¿¼Parallel {\&} Concurrent Haskell 7: GPGPU programming with Accelerate}},
year = {2012},
month = jun
}

@proceedings{ParallelandConcurre:2012vv,
title = {{ï¿¼Parallel {\&} Concurrent Haskell 2: The Par Monad}},
year = {2012},
month = jun
}

@proceedings{ParallelandConcurre:2012wt,
title = {{ï¿¼Parallel {\&} Concurrent Haskell 6: Distributed programming with Cloud Haskell}},
year = {2012},
month = jun
}

@proceedings{Marlow:2012uy,
title = {{ï¿¼Parallel {\&} Concurrent Haskell 5: Server Applications}},
year = {2012},
month = jun
}

@proceedings{ParallelandConcurre:2012te,
title = {{ï¿¼Parallel {\&} Concurrent Haskell 3: Concurrent Haskell}},
year = {2012},
month = jun
}

@article{Sreedhar:1996ct,
author = {Sreedhar, Vugranam C and Gao, Guang R and Lee, Yong-Fong},
title = {{Identifying loops using DJ graphs}},
journal = {ACM Transactions on Programming Languages and Systems},
year = {1996},
volume = {18},
number = {6},
pages = {649--658},
month = nov
}

@article{Oliveira:2012uy,
author = {Oliveira, Bruno C d S and Cook, William R},
title = {{Functional programming with structured graphs}},
journal = {ICFP `12: Proceedings of the 17th ACM SIGPLAN international conference on Functional programming},
year = {2012}
}

@inproceedings{Kennedy:2007cb,
author = {Kennedy, Andrew},
title = {{Compiling with continuations, continued}},
booktitle = {ICFP '07: Proceedings of the 12th ACM SIGPLAN international conference on Functional programming},
year = {2007},
publisher = { ACM  Request Permissions},
month = oct
}

@article{Dubach:2012wc,
author = {Dubach, Christophe and Cheng, Perry and Rabbah, Rodric and Bacon, David and Fink, Stephen},
title = {{Compiling a high-level language for GPUs: (via language support for architectures and compilers)}},
journal = {PLDI '12: Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design and Implementation},
year = {2012}
}

@inproceedings{Benton:2004ua,
author = {Benton, Nick and Kennedy, Andrew and Lindley, Sam and Russo, Claudio},
title = {{Shrinking reductions in SML.NET}},
booktitle = {IFL'04: Proceedings of the 16th international conference on Implementation and Application of Functional Languages},
year = {2004},
publisher = { Springer-Verlag},
month = sep
}

@article{Morrisett:1998vo,
author = {Morrisett, Greg and Walker, David and Crary, Karl and Glew, Neal},
title = {{From System F to Typed Assembly Language}},
journal = {POPL '98: Proceedings of the 25th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
year = {1998}
}

@article{Pham:2006,
author = {Pham, D. C. and Aipperspach, T. and Boerstler, D. and Bolliger, M. and Chaudhry, R. and Cox, D. and Harvey, P. and Harvey, P. M. and Hofstee, H. P. and Johns, C. and Kahle, J. and Kameyama, A. and Keaty, J. and Masubuchi, Y. and Pham, M. and Pille, J. and Posluszny, S. and Riley, M. and Stasiak, D.L. and Suzuoki, M. and Takahashi, O. and Warnock, J. and Weitzel, S. and Wendel, D. and Yazawa, K.},
title = {{Overview of the architecture, circuit design, and physical implementation of a first-generation CELL processor}},
journal = {IEEE Journal of Solid--State Circuits},
year = {2006},
volume = {41},
number = {1},
pages = {179--196},
month = jan
}

@article{Ramsey:2010wd,
author = {Ramsey, Norman and Dias, Joao and Jones, Simon L. Peyton},
title = {{Hoopl: a modular, reusable library for dataflow analysis and transformation}},
journal = {Haskell '10: Proceedings of the third ACM Haskell symposium on Haskell},
year = {2010}
}

@inproceedings{Culler:1994,
author = {Culler, David E and Goldstein, Seth Copen and Schauser, Klaus Erik and Von Eicken, Thorsten},
title = {{Empirical Study of a Dataflow Language on the CM-5}},
booktitle = {Advanced Topics in Dataflow Computing and Multithreading},
year = {1994},
pages = {187--210},
publisher = {IEEE Press}
}

@inproceedings{ScalableComputerVi:2010vq,
author = {Mukhtar, Rami and Lever, Ben and McDonell, Trevor L.},
title = {{Scalable Computer Vision Applications}},
booktitle = {NVIDIA GPU Technology Conference},
year = {2010},
month = sep
}

@article{Thiemann:Es80Kvtr,
author = {Thiemann, Peter and Chakravarty, Manuel M T},
title = {{Agda Meets Accelerate}},
journal = {IFL'12: Proceedings of the 24th international conference on Implementation and Application of Functional Languages},
year = {2012},
month = aug
}

@techreport{Kessenich:2006,
author = {Kessenich, John and Baldwin, Dave and Rost, Randi},
title = {{The OpenGL Shading Language, v1.20}},
year = {2006},
month = sep
}

@article{Skillicorn:1998,
author = {Skillicorn, David B. and Talia, Domenico},
title = {{Models and languages for parallel computation}},
journal = {ACM Computing Surveys},
year = {1998},
volume = {30},
number = {2},
pages = {123--169},
annote = {Survey of parallel programming models, judged based on: * suitability for realistic problems * easy to use \{\&} understand * sound software development methodology * architecture-independent * guarantee performance (parallel execution is deterministic?) * accurate cost model A programming model is an abstract model of computation that is used by the programmer to reason about how a program executes. A processing model is similar, but describes how a physical machine actually performs computation. The goal of any programming language implementation is to efficiently translate a computation expressed relative to the programming model used by the programmer into the processing model used by the target hardware.}
}

@inproceedings{BenLippmeier:2012cd,
author = {Ben Lippmeier and Keller, Gabriele},
title = {{Efficient parallel stencil convolution in Haskell}},
booktitle = {Haskell '11: Proceedings of the 4th ACM symposium on Haskell},
year = {2012},
publisher = { ACM  Request Permissions},
month = jan
}

@article{Barnes:1986,
author = {Barnes, Josh and Hut, Piet},
title = {{A hierarchical $\mathcalO(N \log N)$ force--calculation algorithm}},
journal = {Nature},
year = {1986},
volume = {324},
number = {6096},
pages = {446--449},
month = dec,
annote = {10.1038/324446a0}
}

@inproceedings{Rompf:2013er,
author = {Rompf, Tiark and Sujeeth, Arvind K and Amin, Nada and Brown, Kevin J and Jovanovic, Vojin and Lee, HyoukJoong and Jonnalagedda, Manohar and Olukotun, Kunle and Odersky, Martin},
title = {{Optimizing data structures in high-level programs: new directions for extensible compilers based on staging}},
booktitle = {POPL '13: Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
year = {2013},
publisher = { ACM  Request Permissions},
month = jan
}

@book{Haskell:1998,
editor = {Jones, Simon Peyton},
title = {{Haskell 98 Languages and Libraries: The Revised Report}},
publisher = {Cambridge University Press},
year = {2003},
series = {Haskell 98 Languages and Libraries},
month = apr
}

@inproceedings{Lee:2009uh,
author = {Lee, Sean and Chakravarty, Manuel M T and Grover, Vinod and Keller, Gabriele},
title = {{GPU Kernels as Data-Parallel Array Computations in Haskell}},
booktitle = {Workshop on Exploiting Parallelism using GPUs and other Hardware-Assisted Methods (EPHAM 2009)},
year = {2009},
annote = {This is Sean's work on embedding GPU array computations in Haskell, upon which I will base my research. This work is limited to flat data parallelism, and my goal is to extend this to support nested data parallelism, most likely via the flattening transformation introduced by NESL, and used in DPH. Includes various benchmarks comparing CPU and hand-written GPU implementations. At the time of writing, the system was not complete and some parts of the EDSL were implemented by hand. Presents a reasonable argument for embedding the GPU language in a purely functional language (namely, Haskell) -- stream processing languages based in traditional imperative languages force the developer to limit side effects themselves, whereas pure languages are by-default safe for parallel execution. Uses the Haskell type system to automatically enforce pure GPU kernels and limit the variety of array operations (flat, basic data types). Avoids the need to decompose programs/functions based on architectural constraints rather than standard software engineering considerations. The main limitation of the approach, which is at the same time a key strength, is the high-level nature of the language. While this makes it easy for developers to express their algorithms without being over-burdeneded with parallel implementation details, there is (at least currently) no fine-grain control available for things like data layout and use of the memory hierarchy. As memory bandwidth is usually a major bottleneck, this lack of control could limit the ability to optimise critical sections of an algorithm for best performance.}
}

@article{Lefohn:2006,
author = {Lefohn, Aaron E and Sengupta, Shubhabrata and Kniss, Joe M and Strzodka, Robert and Owens, John D},
title = {{Glift: Generic, efficient, random-access GPU data structures}},
journal = {ACM Transactions on Graphics},
year = {2006},
volume = {25},
number = {1},
pages = {60--99},
annote = {Provides a generic template library that simplifies the design and development of GPU-based data structures.}
}

@inproceedings{Chakravarty:2003tt,
author = {Chakravarty, Manuel M T and Keller, Gabriele},
title = {{An Approach to Fast Arrays in Haskell}},
booktitle = {The Summer School and Workshop on Advanced Functional Programming 2002},
year = {2003},
editor = {Jeuring, Johan and Jones, Simon Peyton},
pages = {27--58},
publisher = {Springer-Verlag},
annote = {Dissects the performance inefficiencies present in the standard Haskell Array type, and proposes a new approach based on program transformation and generic programming (types). Goes through the process of developing an array library including program transformation and fusion operations to generate fast code. Possibly useful mainly as background reference.}
}

@inproceedings{Baskaran:2008,
author = {Baskaran, Muthu Manikandan and Bondhugula, Uday and Krishnamoorthy, Sriram and Ramanujam, J. and Rountev, Atanas and Sadayappan, P.},
title = {{A compiler framework for optimization of affine loop nests for GPGPUs}},
booktitle = {ICS `08: Proceedings of the 22nd annual international conference on Supercomputing},
year = {2008},
pages = {225--234},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{Fisher:1994,
author = {Fisher, Allan L. and Ghuloum, Anwar M.},
title = {{Parallelizing complex scans and reductions}},
journal = {SIGPLAN Notices},
year = {1994},
volume = {29},
number = {6},
pages = {135--146}
}

@inproceedings{Chatterjee:1990vj,
author = {Chatterjee, Siddhartha and Blelloch, Guy E. and Zagha, Marco},
title = {{Scan primitives for vector computers}},
booktitle = {Supercomputing '90., Proceedings of},
year = {1990},
pages = {666--675},
annote = {Describes the use of scan operations to parallelise several irregular problems; sorting, tree traversal/manipulation and a learning algorithm. Interesting background read, could be useful during implementation. In general, presents a model for a data-parallel interpretation of collective array operations. Much of the work is focused on extracting efficient performance for vector machines (Cray Y-MP), so considers effects such as vector length, bank conflicts, etc...}
}

@inproceedings{Zagha:1991kk,
author = {Zagha, Marco and Blelloch, Guy E.},
title = {{Radix sort for vector multiprocessors}},
booktitle = {Supercomputing `91: Proceedings of the 1991 ACM/IEEE conference on Supercomputing},
year = {1991},
pages = {712--721},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Ryoo:2008,
author = {Ryoo, Shane and Rodrigues, Christopher I. and Baghsorkhi, Sara S. and Stone, Sam S. and Kirk, David B. and Hwu, Wen-mei W.},
title = {{Optimization principles and application performance evaluation of a multithreaded GPU using CUDA}},
booktitle = {PPoPP `08: Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming},
year = {2008},
pages = {73--82},
publisher = {ACM},
address = {New York, NY, USA},
annote = {Discusses the practical aspects of writing (or porting) applications and general optimisation strategies for the CUDA architecture. They argue that the key to performance is through massive multithreading to saturate the large number of cores and hide memory access latency, which requires a balance between each thread's resource usage (registers \{\&} shared memory) and the number of simultaneously active threads (in total and per multiprocessor). Performance is also gained by reordering and coalescing off-chip memory access. The major principles they identify to be considered when when choosing code to be executed on the platform are: * leverage zero-overhead thread scheduling to hide memory latency * optimise use of on-chip memory to reduce bandwidth usage and redundant execution * group threads to avoid SIMD penalties and memory port/bank conflicts * there is no built-in global communication mechanism for all threads Related work section provides a good history of data-parallel and GPGPU programming models. Detailed running example of optimising matrix-matrix multiplication, then present \{\&} discuss the results of a number of other applications. Several interesting insights to the complexity of optimisation for the platform * small changes have multiplicative resource usage effects (due to the large number of threads), which can cause fewer thread blocks to be simultaneously executed. * relatively easy to be "trapped" in a local maximum when hand optimising code -- may need to try widely varying configurations to find satisfactory performance. * the primary concern is often managing global memory latency, as global memory bandwidth can limit the throughput of the system}
}

@techreport{Sengupta:2008ut,
author = {Sengupta, Shubhabrata and Harris, Mark and Garland, Michael},
title = {{Efficient Parallel Scan Algorithms for GPUs}},
year = {2008},
month = dec
}

@inproceedings{Kruger:2005,
author = {Kr u ger, Jens and Westermann, R\"{u}diger},
title = {{Linear algebra operators for GPU implementation of numerical algorithms}},
booktitle = {SIGGRAPH `05: ACM SIGGRAPH 2005 Courses},
year = {2005},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Chakravarty:2005dx,
author = {Chakravarty, Manuel M T and Keller, Gabriele and Jones, Simon Peyton},
title = {{Associated type synonyms}},
booktitle = {ICFP `05: Proceedings of the tenth ACM SIGPLAN international conference on Functional programming},
year = {2005},
pages = {241--253},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Jones:2008uu,
author = {Jones, Simon Peyton and Leshchinskiy, Roman and Keller, Gabriele and Chakravarty, Manuel M T},
title = {{Harnessing the Multicores: Nested Data Parallelism in Haskell}},
booktitle = {Foundations of Software Technology and Theoretical Computer Science},
year = {2008},
editor = {Hariharan, R and Mukund, M and Vinay, V},
month = oct,
annote = {Summary paper for earlier publications. Provides tutorials for programmers and of the vectorisation transformation. - Flattening Trees - More types for nested data parallel programming - Higher order flattening - Data parallel haskell: a status report}
}

@article{Prins:1999,
author = {Prins, Jan F. and Chatterjee, Siddhartha and Simons, Martin},
title = {{Irregular Computations in Fortran -- Expression and Implementation Strategies}},
journal = {Scientific Programming},
year = {1999},
volume = {7},
number = {3},
pages = {313--326}
}

@techreport{Bell:2008,
author = {Bell, Nathan and Garland, Michael},
title = {{Efficient Sparse Matrix-Vector Multiplication on CUDA}},
year = {2008}
}

@article{Govindaraju:2007,
author = {Govindaraju, Naga K and Manocha, Dinesh},
title = {{Cache-efficient numerical algorithms using graphics hardware}},
journal = {Parallel Computing},
year = {2007},
volume = {33},
number = {10-11},
pages = {663--684}
}

@article{Marcotte:2007,
author = {Marcotte, Edward M},
title = {{How do shotgun protoemics algorithms identify proteins?}},
journal = {Nature Biotechnology},
year = {2007},
volume = {25},
number = {7},
pages = {755--757}
}

@inproceedings{Mainland:2007bl,
author = {Mainland, Geoffrey},
title = {{Why it's nice to be quoted}},
booktitle = {the ACM SIGPLAN workshop},
year = {2007},
pages = {73},
publisher = {ACM Press},
address = {New York, New York, USA}
}

@inproceedings{Meijer:1991,
author = {Meijer, Erik and Fokkinga, Maarten and Paterson, Ross},
title = {{Functional programming with bananas, lenses, envelopes and barbed wire}},
booktitle = {Proceedings of the 5th ACM conference on Functional programming languages and computer architecture},
year = {1991},
pages = {124--144},
publisher = {Springer-Verlag New York, Inc.},
address = {New York, NY, USA}
}

@techreport{Appel:1994ws,
author = {Appel, Andrew W and Jim, Trevor},
title = {{Making Lambda Calculus Smaller, Faster}},
year = {1994},
number = {CS-TR-477-94},
month = nov
}

@inproceedings{Jones:2009,
author = {Jones Jr, Don and Marlow, Simon and Singh, Satnam},
title = {{Parallel performance tuning for Haskell}},
booktitle = {Haskell `09: Proceedings of the 2nd ACM SIGPLAN symposium on Haskell},
year = {2009},
pages = {81--92},
publisher = {ACM},
address = {New York, NY, USA},
annote = {Describes ThreadScope and its use to improve the performance of semi-implicit parallel programs (par, pseq) through case study discussion.}
}

@inproceedings{Lippmeier:2012vv,
author = {Lippmeier, Ben and Chakravarty, Manuel M T and Keller, Gabriele and Jones, Simon Peyton},
title = {{Guiding parallel array fusion with indexed types}},
booktitle = {Haskell '12: Proceedings of the 2012 symposium on Haskell symposium},
year = {2013},
publisher = { ACM  Request Permissions},
month = jan
}

@inproceedings{Sweeney:2006,
author = {Sweeney, Tim},
title = {{The next mainstream programming language: a game developer's perspective}},
booktitle = {POPL `06: Conference record of the 33rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
year = {2006},
pages = {269--269},
publisher = {ACM},
address = {New York, NY, USA},
annote = {Invited talk by Tim Sweeney (Epic Games) "In a concurrent world, imperative is the wrong default!"}
}

@book{Aho:2006wb,
author = {Aho, Alfred V and Lam, Monica S and Sethi, Ravi and Ullman, Jeffrey D},
title = {{Compilers: Principles, Techniques, and Tools (2nd Edition)}},
publisher = {Prentice Hall},
year = {2006},
edition = {2},
month = sep
}

@article{Cederman:2009,
author = {Cederman, Daniel and Tsigas, Philippas},
title = {{GPU-Quicksort: A practical Quicksort algorithm for graphics processors}},
journal = {Journal of Experimental Algorithmics},
year = {2009},
volume = {14},
pages = {1.4--1.24}
}

@article{Jones:2001wm,
author = {Jones, Simon Peyton and Tolmach, Andrew and Hoare, Tony},
title = {{Playing by the Rules: Rewriting as a practical optimization technique in GHC}},
journal = {In Proceedings of the 2001 Haskell Workshop},
year = {2001},
pages = {203--233},
month = sep
}

@inproceedings{Ernst:2004,
author = {Ernst, Manfred and Vogelgsang, Christian and Greiner, G u nther},
title = {{Stack Implementation on Programmable Graphics Hardware}},
booktitle = {Proceedings of the Vision, Modeling and Visualisation Conference},
year = {2004},
editor = {Girod, Bernd and Magnor, Marcus Andreas and Seidel, Hans-Peter},
pages = {255--262},
month = nov
}

@techreport{Chakravarty:2009uo,
author = {Chakravarty, Manuel M T},
title = {{Converting a HOAS term GADT into a de Bruijn term GADT}},
year = {2009}
}

@article{McCool:2004,
author = {McCool, Michael D and Du Toit, Stefanus and Popa, Tiberiu and Chan, Bryan and Moule, Kevin},
title = {{Shader algebra}},
journal = {ACM Transactions on Graphics},
year = {2004},
volume = {23},
number = {3},
pages = {787--795},
annote = {A GPU programming model for general-purpose computation that is more convenient than graphics-oriented development environments of high-level shading languages (pre-cuda). Based on C++ meta-programming, uses reflection to dynamically compile an EDSL for the GPU.}
}

@article{Moore:1965wc,
author = {Moore, Gordon Earle},
title = {{Craming more components onto integrated circuits}},
journal = {Electronics},
year = {1965},
volume = {38},
number = {8}
}

@inproceedings{Jiang:2005,
author = {Jiang, Changhao and Snir, Marc},
title = {{Automatic Tuning Matrix Multiplication Performance on Graphics Hardware}},
booktitle = {PACT `05: Proceedings of the 14th International Conference on Parallel Architectures and Compilation Techniques},
year = {2005},
pages = {185--196},
publisher = {IEEE Computer Society},
address = {Washington, DC, USA}
}

@inproceedings{McCool:2006,
author = {McCool, Michael D},
title = {{Data--Parallel Programming on the Cell BE and the GPU using the RapidMind Development Platform}},
booktitle = {GSPx Multicore Applications Conference},
year = {2006},
address = {Santa Clara},
month = oct,
annote = {A C++ class library that provides new data types and captures a series of operations that are translated into low-level GPU instructions.}
}

@inproceedings{Coutts:2007kp,
author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
title = {{Stream fusion: from lists to streams to nothing at all}},
booktitle = {ICFP `07: Proceedings of the 12th ACM SIGPLAN international conference on Functional programming},
year = {2007},
pages = {315--326},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{Sutter:2005,
author = {Sutter, Herb},
title = {{The Free Lunch is Over: A Fundamental Turn Toward Concurrency in Software}},
journal = {Dr. Dobbs Journal},
year = {2005},
volume = {30},
number = {3},
month = mar
}

@article{Blelloch:1996jx,
author = {Blelloch, Guy E. and Greiner, John},
title = {{A provable time and space efficient implementation of NESL}},
journal = {SIGPLAN Notices},
year = {1996},
volume = {31},
number = {6},
pages = {213--225}
}

@article{Hudak:1996,
author = {Hudak, Paul},
title = {{Building domain-specific embedded languages}},
journal = {ACM Computing Surveys},
year = {1996},
volume = {28},
number = {4es},
pages = {196},
annote = {A short treatise that advocates the use of domain-specific embedded languages as the "ultimate abstraction". Argues that the problem of building and gracefully evolving large and complex software systems is easiest when the programming language is designed to precisely capture the semantics of the application domain -- no more and no less.}
}

@techreport{UPC:2005,
author = {{UPC Consortium}},
title = {{UPC Language Specification, v1.2}},
year = {2005},
month = may
}

@article{Puschel:2005,
author = {P u schel, Markus and Moura, Jos\'{e} M. F. and Johnson, Jeremy R. and Padua, David and Veloso, Manuela M. and Singer, Bryan W. and Xiong, Jianxin and Franchetti, Franz and Ga v c i c, Aca and Voronenko, Yevgen and Chen, Kang and Johnson, Robert W. and Rizzolo, Nicholas},
title = {{SPIRAL: Code Generation for DSP Transforms}},
journal = {Proceedings of the IEEE},
year = {2005},
volume = {93},
number = {2},
pages = {232--275},
month = feb,
annote = {Develops methods and tools for automatically generating high performance libraries. The tuning of an algorithm for a given platform is expressed as an optimisation problem, and the domain specific mathematical structure of the algorithm is used to create a feedback--driven optimiser. Based on the algebra of combinators? Could be interesting (much later...)}
}

@inproceedings{Wang:2007,
author = {Wang, Perry H. and Collins, Jamison D. and Chinya, Gautham N. and Jiang, Hong and Tian, Xinmin and Girkar, Milind and Yang, Nick Y. and Lueh, Guei-Yuan and Wang, Hong},
title = {{EXOCHI: architecture and programming environment for a heterogeneous multi-core multithreaded system}},
booktitle = {PLDI `07: Proceedings of the 2007 ACM SIGPLAN conference on Programming language design and implementation},
year = {2007},
pages = {156--166},
publisher = {ACM},
address = {New York, NY, USA},
annote = {Platform developed by intel to program heterogenous environments consisting of general purpose CPUs and specialised accelerator units such as GPUs. Consists of two components: * an architecture to represent heterogenous accelerators as ISA-based MIMD resources, with a shared virtual-memory multithreaded execution model * an integrated C/C++ environment that supports accelerator-specific instructions in a single binary, with a runtime system that can optimally spread the parallel computation across the available cores. Differers from the CUDA model, in which the GPU has a separate device address space, and all CPU/GPU communication and synchronisation is explicit.}
}

@techreport{Blelloch:1990vl,
author = {Blelloch, Guy E.},
title = {{Prefix Sums and Their Applications}},
year = {1990},
number = {CMU-CS-90-190},
month = nov
}

@article{McCormick:2007,
author = {McCormick, Patrick and Inman, Jeff and Ahrens, James and Mohd-Yusof, Jamaludin and Roth, Greg and Cummins, Sharen},
title = {{Scout: A data-parallel programming language for graphics processors}},
journal = {Parallel Computing},
year = {2007},
volume = {33},
number = {10--11},
pages = {648--662},
annote = {Scout is designed as a portable language for programming GPUs in the stream processing model (flat data-parallel, SPMD), that includes constructs for both general-purpose computation as well as data visualisation. This strategy hides the nuances of both the underlying hardware and supporting graphics layer, providing users the ability to simultaneously process and interact with data from a single unified language. Two examples of combined combination/visualisation are provided, which show the programming model to be straight-forward and concise. No comparisons or benchmarks to hand-optimised code are provided. Good summary of related work, both for data-parallel languages and visualisation, including comparisons to the various applicable components of Scout. No competing compute+visualise system was mentioned, so seems to be a fairly unique contribution. Clear on how their ideas derive from or extend related works. Possibly applicable to my work, there is some discussion of how the Scout language is transformed into an intermediate representation, which is analysed for control/data flow in a directed graph / single static assignment, to locate {\&} combine parallel regions, and reduce memory traffic between CPU and GPU. They are also aiming at a slightly higher level of abstraction (as I also will be) than most GPU programming languages, which focus on kernel writing. The core system seems to be base on the old pre-CUDA graphics-API paradigm, so lacks support for new features such as data scatter. The authors mention this may be investigated in the future (although that could make the platform vendor-specific).}
}

@article{Eng:2008,
author = {Eng, Jimmy K and Fischer, Bernd and Grossmann, Jonas and MacCoss, Michael J},
title = {{A Fast SEQUEST Cross Correlation Algorithm}},
journal = {Journal of Proteome Research},
year = {2008},
volume = {7},
number = {10},
pages = {4598--4602}
}

@article{Cole:2012ww,
author = {Cole, Alex and McEwan, Alistair and Mainland, Geoffrey},
title = {{Beauty and the Beast: Exploting GPUs in Haskell}},
journal = {Communicating Process Architectures},
year = {2012},
pages = {121--134},
month = aug
}

@book{Plasmeijer:2002,
author = {Plasmeijer, Rinus and van Eekelen, Marko},
title = {{Clean Language Report, v2.1}},
publisher = {Department of Software Technology, University of Nijmegen},
year = {2002},
month = nov
}

@inproceedings{Chakravarty:1999vx,
author = {Chakravarty, Manuel M T and Keller, Gabriele},
title = {{How Portable is Nested Data Parallelism?}},
booktitle = {Proceedings of the 6th Annual Australasian Conference on Parallel And Real-Time Systems (PART `99)},
year = {1999},
editor = {Cheng, W and Sajeev, A S M},
publisher = {Springer-Verlag},
annote = {Demonstrates that nested data-parallel languages can be used to generate efficient code on a wide range of architectures (distributed vs. shared memory, and scalar vs. vector processors). Essentially combines the flattening transformation, to convert a nested parallel program into an equivalent flat program without reducing the parallelism specified in the original program, together with calculational fusion (deforestation) to remove unnecessary intermediate data structures. The deforestation and code generation phases are parameterised for the target architecture. A structured communication library is provided which handles one-way collective communication operations.}
}

@techreport{CTM:2006,
author = {{AMD}},
title = {{ATI CTM Guide, v1.01}},
year = {2006},
month = nov,
annote = {Deprecated.}
}

@inproceedings{Marlow:2006,
author = {Marlow, Simon},
title = {{An extensible dynamically-typed hierarchy of exceptions}},
booktitle = {Haskell `06: Proceedings of the 2006 ACM SIGPLAN workshop on Haskell},
year = {2006},
pages = {96--106},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Strzodka:2004,
author = {Strzodka, R and Telea, A},
title = {{Generalized Distance Transforms and Skeletons in Graphics Hardware}},
booktitle = {Proceedings of the EUROGRAPHICS/IEEE TCVG Symposium on Visualization (VisSym `04)},
year = {2004},
editor = {Deussen, O and Hansen, C and Keim, D A and Saupe, D},
pages = {221--230}
}

@article{Williams:2009,
author = {Williams, Samuel and Oliker, Leonid and Vuduc, Richard and Shalf, John and Yelick, Katherine and Demmel, James},
title = {{Optimization of sparse matrix-vector multiplication on emerging multicore platforms}},
journal = {Parallel Computing},
year = {2009},
volume = {35},
number = {3},
pages = {178--194}
}

@article{Bjesse:1999em,
author = {Bjesse, Per and Claessen, Koen and Sheeran, Mary and Singh, Satnam},
title = {{Lava: Hardware design in Haskell}},
journal = {SIGPLAN Notices},
year = {1999},
volume = {34},
number = {1},
pages = {174--184}
}

@article{Sutter:2005a,
author = {Sutter, Herb and Larus, James},
title = {{Software and the Concurrency Revolution}},
journal = {ACM Queue},
year = {2005},
volume = {3},
number = {7},
pages = {54--62}
}

@article{Sipelstein:1991fp,
author = {Sipelstein, Jay M. and Blelloch, Guy E.},
title = {{Collection-oriented languages}},
journal = {Proceedings of the IEEE},
year = {1991},
volume = {79},
number = {4},
pages = {504--523},
month = apr
}

@article{Subhlok:1997,
author = {Subhlok, Jaspal and Yang, Bwolen},
title = {{A new model for integrated nested task and data parallel programming}},
journal = {SIGPLAN Notices},
year = {1997},
volume = {32},
number = {7},
pages = {1--12}
}

@article{Chatterjee:1993,
author = {Chatterjee, Siddhartha},
title = {{Compiling nested data-parallel programs for shared-memory multiprocessors}},
journal = {ACM Transactions on Programming Languages and Systems},
year = {1993},
volume = {15},
number = {3},
pages = {400--462}
}

@inproceedings{Fatahalian:2006,
author = {Fatahalian, Kayvon and Horn, Daniel Reiter and Knight, Timothy J. and Leem, Larkhoon and Houston, Mike and Park, Ji Young and Erez, Mattan and Ren, Manman and Aiken, Alex and Dally, William J. and Hanrahan, Pat},
title = {{Sequoia: programming the memory hierarchy}},
booktitle = {SC `06: Proceedings of the 2006 ACM/IEEE conference on Supercomputing},
year = {2006},
pages = {83},
publisher = {ACM},
address = {New York, NY, USA},
annote = {Data-parallel language that adds the concepts of tunables and recursion over the memory hierarchy in order to better exploit memory locality. This permits code to be structured so that a recursive problem can be conveniently mapped onto the many levels of parallelism and memory in a parallel processor.}
}

@article{Myer:1968,
author = {Myer, T. H. and Sutherland, I. E.},
title = {{On the design of display processors}},
journal = {Communications of the ACM},
year = {1968},
volume = {11},
number = {6},
pages = {410--414},
annote = {Wheel of reincarnation: Term used to refer to a well-known effect whereby function in a computing system family is migrated out to special-purpose peripheral hardware for speed, then the peripheral evolves toward more computing power as it does its job, then somebody notices that it is inefficient to support two asymmetrical processors in the architecture and folds the function back into the main CPU, at which point the cycle begins again}
}

@techreport{Glaskowsky:2009,
author = {Glaskowsky, Peter N.},
title = {{NVIDIA's Fermi: The First Complete GPU Computing Architecture}},
year = {2009},
month = sep
}

@inproceedings{Ueng:2008,
author = {Ueng, Sain-Zee and Lathara, Melvin and Baghsorkhi, Sara S. and Hwu, Wen-mei W.},
title = {{CUDA-Lite: Reducing GPU Programming Complexity}},
booktitle = {Languages and Compilers for Parallel Computing},
year = {2008},
pages = {1--15},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
month = nov,
annote = {A source-to-source transformation that takes a (straightforward) implementation of a CUDA kernel that utilises only global memory, and optimises the memory performance. Requires some programmer annotations, and currently does not use constant or texture memory. The main focus is coalescing global memory access -- threads in a block sync and load all data (coalesced) into shared memory, regardless or not if there is data reuse (although it appears annotations exist for a tiling transformation) Newer hardware generations have significantly relaxed memory access coalescing rules...}
}

@inproceedings{McBride:2004jt,
author = {McBride, Conor and McKinna, James},
title = {{I am not a number -- I am a free variable}},
booktitle = {Haskell `04: Proceedings of the 2004 ACM SIGPLAN workshop on Haskell},
year = {2004},
pages = {1--9},
publisher = {ACM},
address = {New York, NY, USA},
annote = {http://www.e-pig.org/epilogue/?p=773}
}

@article{Barrett:2008,
author = {Barrett, R. F. and Alam, S. R. and Almeida, V. F. d. and Bernholdt, D. E. and Elwasif, W. R. and Kuehn, J. A. and Poole, S. W. and Shet, A. G.},
title = {{Exploring HPCS languages in scientific computing}},
journal = {Journal of Physics Conference Series},
year = {2008},
volume = {125},
number = {1},
pages = {12034},
annote = {Compares three HPC languages under development, Chapel, Fortress, and X10. These are new, high-level languages with support for object oriented and generic programming, and provide a broad range of contstructs for expressing both task and data parallelism at multiple levels, with a global view of data. A good background on related (now, historical) work. MPI combined with a sequential language, often coupled with OpenMP as well. Failure of HPF, an early attempt at a truly parallel language that pushed too far, too soon. CAF, UPC and Titanium, which provide only minimal extensions to their base languages. ZPL, which demonstrated a high-level approach to array operations (s.c. NESL?). Provides two fairly detailed examples of parallel expression in these languages with a finite difference problem (PDE: data decomposition), and Hartree-Fock algorithm (task parallelism of distributed data). Describes different features the languages support to express these types of parallelism easily. Provides a decent outline of these languages. Optimistic about new features, but (sensibly) cautions that the languages are not yet mature enough for a reasonable evaluation to long-standing approaches.}
}

@inproceedings{Elliott:2004,
author = {Elliott, Conal},
title = {{Programming graphics processors functionally}},
booktitle = {Haskell '04: Proceedings of the 2004 ACM SIGPLAN workshop on Haskell},
year = {2004},
publisher = { ACM  Request Permissions},
month = sep,
annote = {Vertigo, an embedded functional graphics language in Haskell.}
}

@article{Laemmel:2002wj,
author = {Laemmel, Ralf},
title = {{Typed Generic Traversal With Term Rewriting Strategies}},
journal = {arXiv.org},
year = {2002},
eprint = {cs/0205018v2},
eprinttype = {arxiv},
eprintclass = {cs.PL},
month = may,
annote = {85 pages, submitted for publication to the Journal of Logic and
  Algebraic Programming}
}

@article{Olukotun:2005,
author = {Olukotun, Kunle and Hammond, Lance},
title = {{The Future of Microprocessors}},
journal = {ACM Queue},
year = {2005},
volume = {3},
number = {7},
pages = {26--29},
annote = {Seems to be a high-level overview of the trend in the semiconductor industry -- limits of single-thread performance, and that CPUs are clearly evolving in the same direction: towards massive parallelism and "many-core" architectures.}
}

@book{Cole:1989,
author = {Cole, Murray I},
title = {{Algorithmic Skeletons: Structured Management of Parallel Computation}},
publisher = {The MIT Press},
year = {1989},
annote = {Use a two-level language where parallel programs are decomposed into templates encoding a fixed parallel structure, and scalar code that is injected at predefined points into that structure.}
}

@inproceedings{Sengupta:2007a,
author = {Sengupta, Shubhabrata and Lefohn, Aaron E and Owens, John D},
title = {{A work--efficient step--efficient prefix--sum algorithm}},
booktitle = {Proceedings of the Workshop on Edge Computing Using New Commodity Architectures},
year = {2007},
pages = {26--27},
month = aug,
annote = {A prefix-sum implementation for GPUs shown to be more efficient than that of Horn:2005 (GPU Gems 2).}
}

@mastersthesis{Svensson:2008,
author = {Svensson, Joen and Claessen, Koen and Sheeran, Mary},
title = {{Obsidian: An embedded language for data--parallel programming}},
school = {Department of Computer Science and Engineering, Chalmers University of Technology},
year = {2008}
}

@inproceedings{Chan:2002,
author = {Chan, Eric and Ng, Ren and Sen, Pradeep and Proudfoot, Kekoa and Hanrahan, Pat},
title = {{Efficient partitioning of fragment shaders for multipass rendering on programmable graphics hardware}},
booktitle = {HWWS `02: Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware},
year = {2002},
pages = {69--78},
publisher = {Eurographics Association},
address = {Aire-la-Ville, Switzerland, Switzerland},
annote = {A polynomial-time algorithm for partitioning fragment shaders into multiple phases. Find near-optimal partitions for a number of shaders on architectures with different resources limitations and different cost models. Could be applicable for my work.}
}

@book{Chatterjee:2009vh,
author = {Chatterjee, Siddhartha and Prins, Jan},
title = {{COMP663: Parallel Computing Algorithms}},
publisher = {Department of Computer Science, University of North Carolina at Chapel Hill},
year = {2009}
}

@inproceedings{Batcher:1968,
author = {Batcher, Kenneth E.},
title = {{Sorting networks and their applications}},
booktitle = {AFIPS `68: Proceedings of the Spring Joint Computer Conference},
year = {1968},
pages = {307--314},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{PeytonJones:1998ix,
author = {Peyton Jones, Simon and Santos, Andr{\'e} L M},
title = {{A transformation-based optimiser for Haskell}},
journal = {Science of Computer Programming},
year = {1998},
volume = {32},
number = {1-3},
pages = {3--47},
month = sep
}

@article{Chamberlain:2007,
author = {Chamberlain, Bradford L and Callahan, David and Zima, Hans P},
title = {{Parallel programmability and the Chapel language}},
journal = {International Journal of High Performance Computing Applications},
year = {2007},
volume = {21},
number = {3},
pages = {291--312},
month = sep,
annote = {Provide an overview of data-parallel programming languages, breaking down languages by their design principles. Defines parallel programming productivity as a combination of performance, programmability, portability and robustness. Describes their work on the language Chapel, which strives to impact positively in all of these areas. Argues that as many data-parallel languages require programmers to write in a SPMD style, makes it difficult to express nested data or data/task parallelism. Such fragmented programming models make it fairly easy to understand and reason about, but require programmers to express algorithms on a task-by-task basis, explicitly decomposing data structures and control flow into per-task chunks. Rather negative of SPMD. Expounds the global programming model, expressing algorithms and data structures as a whole without needing to specify the mapping onto threads (or specifying only when necessary for performance-critical sections). Supports many other data/task parallelism initiatives.}
}

@article{Blelloch:1998eo,
author = {Blelloch, Guy E. and Leiserson, C. E. and Maggs, B. M. and Plaxton, C. G. and Smith, S. J. and Zagha, M.},
title = {{An Experimental Analysis of Parallel Sorting Algorithms}},
journal = {Theory of Computing Systems},
year = {1998},
volume = {31},
number = {2},
pages = {135--167},
month = apr
}

@inproceedings{Keller:1996,
author = {Keller, Gabriele and Simons, Martin},
title = {{A calculational approach to flattening nested data parallelism in functional languages}},
booktitle = {ASIAN `96: Proceedings of the Second Asian Computing Science Conference on Concurrency and Parallelism, Programming, Networking, and Security},
year = {1996},
editor = {Jaffar, J},
pages = {234--243},
publisher = {Springer-Verlag}
}

@inproceedings{Chakravarty:2000bk,
author = {Chakravarty, Manuel M T and Keller, Gabriele},
title = {{More types for nested data parallel programming}},
booktitle = {ICFP `00: Proceedings of the fifth ACM SIGPLAN international conference on Functional programming},
year = {2000},
pages = {94--105},
publisher = {ACM},
address = {New York, NY, USA}
}

@phdthesis{Randall:1998,
author = {Randall, Keith H.},
title = {{Cilk: Efficient Multithreaded Computing}},
school = {Massachusetts Institute of Technology},
year = {1998},
address = {Cambridge, MA, USA},
month = jun,
annote = {An extension to C that supports very lightweight tasks by a generalisation of the idea of a function call. Uses an efficient load-balancing strategy called work stealing that minimises communication between processors.}
}

@book{MPI:2008,
author = {{Message Passing Interface Forum}},
title = {{MPI: A Message-Passing Interface Standard, v2.1}},
publisher = {High Performance Computing Center Stuttgart (HLRS)},
year = {2008},
month = jun
}

@article{Numrich:1998,
author = {Numrich, Robert W. and Reid, John},
title = {{Co-array Fortran for parallel programming}},
journal = {SIGPLAN Fortran Forum},
year = {1998},
volume = {17},
number = {2},
pages = {1--31}
}

@phdthesis{Keller:1999,
author = {Keller, Gabriele},
title = {{Transformation-based Implementation of Nested Data Parallelism for Distributed Memory Machines}},
school = {Technische Universit\"at Berlin, Fachbereich Informatik},
year = {1999}
}

@inproceedings{Ryoo:2007,
author = {Ryoo, Shane and Rodrigues, Christopher I. and Stone, Sam S. and Baghsorkhi, Sara S. and Ueng, Sain-Zee and Hwu, Wen-mei W.},
title = {{Program optimization study on a 128-core GPU}},
booktitle = {The First Workshop on General Purpose Processing on Graphics Processing Units},
year = {2007},
month = oct,
annote = {Presents an exhaustive search of the optimisation space for several applications, explaining the effects that optimisations can have on the [GeForce 8-series] architecture and how it differs from more traditional architectures. Small changes in resource per thread can have very significant performance ramifications. Hence, maximizing computational efficiency can be challenging, due to discontinuities in the optimisation space.}
}

@inproceedings{Blelloch:1988iu,
author = {Blelloch, Guy E. and Sabot, Gary W},
title = {{Compiling collection-oriented languages onto massively parallel computers}},
booktitle = {Proceedings of the 2nd Symposium on the Frontiers of Massively Parallel Computation},
year = {1988},
pages = {575--585},
month = oct,
annote = {Collection-oriented languages are characterised by the use of operations on aggregate data structures (arrays, vectors, lists, sets...) that manipulate the structure as a whole. This work focuses on techniques for mapping nested parallel constructs onto flat parallel execution models, and forms the basis for NDP.}
}

@article{Kennedy:2007vo,
author = {Kennedy, Andrew},
title = {{Compiling with continuations, continued}},
journal = {ACM SIGPLAN NOTICES},
year = {2007},
volume = {42},
number = {9},
pages = {177}
}

@article{Callahan:2004,
author = {Callahan, David and Carr, Steve and Kennedy, Ken},
title = {{Improving register allocation for subscripted variables}},
journal = {SIGPLAN Notices},
year = {2004},
volume = {39},
number = {4},
pages = {328--342},
annote = {Algorithm to identify reuse in array references in an innermost loop, so that these values could be placed into registers. Also demonstrated a way to expose more opportunities for scalar replacement by moving reuse occurrences across an outer loop into an innermost loop. This addressed deficiencies of register allocation schemes of the time when applied to arrays (especially common in scientific codes).}
}

@inproceedings{Foley:2005,
author = {Foley, Tim and Sugerman, Jeremy},
title = {{KD-tree acceleration structures for a GPU raytracer}},
booktitle = {Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware (HWWS `05)},
year = {2005},
pages = {15--22},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{Bird:1999bj,
author = {Bird, Richard S and Paterson, Ross},
title = {{De Bruijn notation as a nested datatype}},
journal = {Journal of Functional Programming},
year = {1999},
volume = {9},
number = {1},
pages = {77--91},
month = jan
}

@inproceedings{Leshchinskiy:2006jw,
author = {Leshchinskiy, Roman and Chakravarty, Manuel M T and Keller, Gabriele},
title = {{Higher Order Flattening}},
booktitle = {Third International Workshop on Practical Aspects of High-Level Parallel Programming (PAPP 2006)},
year = {2006},
pages = {920--928},
publisher = {Springer-Verlag}
}

@inproceedings{Palmer:1995,
author = {Palmer, D. W. and Prins, J. F. and Westfold, S.},
title = {{Work-efficient nested data-parallelism}},
booktitle = {FRONTIERS `95: Proceedings of the Fifth Symposium on the Frontiers of Massively Parallel Computation (Frontiers'95)},
year = {1995},
pages = {186--193},
publisher = {IEEE Computer Society},
address = {Washington, DC, USA}
}

@inproceedings{Chakravarty:2005kg,
author = {Chakravarty, Manuel M T and Keller, Gabriele and Jones, Simon Peyton and Marlow, Simon},
title = {{Associated types with class}},
booktitle = {Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL `05)},
year = {2005},
pages = {1--13},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Jones:2007,
author = {Jones, Simon Peyton and Wadler, Philip},
title = {{Comprehensive comprehensions: comprehensions with `Order by' and `Group by'}},
booktitle = {Haskell `07: Proceedings of the ACM SIGPLAN Haskell workshop},
year = {2007},
pages = {61--72},
address = {Freiburg, Germany}
}

@inproceedings{Foltzer:2012dk,
author = {Foltzer, Adam and Kulkarni, Abhishek and Swords, Rebecca and Sasidharan, Sajith and Jiang, Eric and Newton, Ryan},
title = {{A meta-scheduler for the par-monad: composable scheduling for the heterogeneous cloud}},
booktitle = {ICFP '12: Proceedings of the 17th ACM SIGPLAN international conference on Functional programming},
year = {2012},
publisher = { ACM  Request Permissions},
month = sep
}

@inproceedings{Marlow:2009,
author = {Marlow, Simon and Jones, Simon Peyton and Singh, Satnam},
title = {{Runtime Support for Multicore Haskell}},
booktitle = {ICFP `09: Proceedings of the 14th ACM SIGPLAN international conference on Functional programming},
year = {2009}
}

@inproceedings{Kennedy:2007,
author = {Kennedy, Ken and Koelbel, Charles and Zima, Hans},
title = {{The rise and fall of High Performance Fortran: an historical object lesson}},
booktitle = {HOPL III: Proceedings of the third ACM SIGPLAN conference on History of programming languages},
year = {2007},
pages = {7--1--7--22},
publisher = {ACM},
address = {New York, NY, USA},
annote = {An interesting read. Analyses the failure of HPF, proposing several key features and strategies that should be employed by future high--performance languages in order to avoid the same pitfalls and learn from the experience. Specifically: - immature compiler technology leading to poor performance - lack of flexible [data] distributions - inconsistent implementations - missing tools (library) - lack of patience by the community Nevertheless, HPF introduced a number of important features that have been incorporated into newer languages, such as the single-threaded execution model with globally addressable memory space.}
}

@article{Hillis:1986,
author = {Hillis, W. Daniel and Steele Jr, Guy L},
title = {{Data parallel algorithms}},
journal = {Communications of the ACM},
year = {1986},
volume = {29},
number = {12},
pages = {1170--1183},
annote = {Describes several data-parallel algorithms appropriate for fine-grained parallel computers with general communications, where parallelism comes from simultaneous operation across large sets of data, rather than from multiple threads of control. A good argument for the applicability of data parallelism: intuition will initially lead to the assumption that data parallel algorithms are suitable only for very regular calculations in simulation and search. The paper argues that this is in fact an appropriate style whenever the amount of data to be operated upon is very large -- if the number of lines of code is fixed and the amount of data is allowed to grow arbitrarily, the ratio of code to data will necessarily approach zero. The parallelism to be gained by concurrently operating on multiple data elements will therefore be greater than the parallelism to be gained by concurrently executing lines of code. * parallel combinator reduction (can be used to simulate control parallelism) * all partial sums (prefix-scan) * count/enumerate active processors (filter?) * radix sort * string parsing * find the end of a linked list (seems to require that each element of the linked list is associated with a processor, and then all processors work together to find the end of the list in O(n log n) time) * all partial sums of a linked list * matching up elements of two linked lists (?) * region labeling (CC) * some discussion of nested data parallelism A seminal paper for data parallel computing. Possibly useful to my work for some fundamental ideas for designing algorithms. Examples focus on vector computers, but the segmented/prefix-scan is still valid today.}
}

@inproceedings{Peercy:2006,
author = {Peercy, Mark and Segal, Mark and Gerstmann, Derek},
title = {{A performance-oriented data parallel virtual machine for GPUs}},
booktitle = {SIGGRAPH `06: ACM SIGGRAPH 2006 Sketches},
year = {2006},
pages = {184},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{Lamport:1978,
author = {Lamport, Leslie},
title = {{Time, clocks, and the ordering of events in a distributed system}},
journal = {Communications of the ACM},
year = {1978},
volume = {21},
number = {7},
pages = {558--565}
}

@inproceedings{Jones:2006eh,
author = {Jones, Simon Peyton and Vytiniotis, Dimitrios and Weirich, Stephanie and Washburn, Geoffrey},
title = {{Simple unification-based type inference for GADTs}},
booktitle = {ICFP `06: Proceedings of the eleventh ACM SIGPLAN international conference on Functional programming},
year = {2006},
pages = {50--61},
publisher = {ACM},
address = {New York, NY, USA},
annote = {GADTs are used to generate the abstract syntax tree in the current GPU EDSL.}
}

@article{Hamada:2008,
author = {Hamada, Tsuyoshi and Iitaka, Toshiaki},
title = {{The Chamomile Scheme: An Optimized Algorithm for N-body simulations on Programmable Graphics Hardware}},
journal = {New Astronomy},
year = {2008},
month = jul,
annote = {Hierarchical n-body problem for GPUs.}
}

@techreport{Xu:2003,
author = {Xu, Dana N. and Khoo, Siau-Chen and Chin, Wei-Ngan and Hu, Zhenjiang},
title = {{A Type-Based Approach to Parallelization}},
year = {2003}
}

@article{Park:2008,
author = {Park, Christopher Y and Klammer, Aaron A and K{\"a}ll, Lukas and MacCoss, Michael J and Noble, William Stafford},
title = {{Rapid and accurate peptide identification from tandem mass spectra}},
journal = {Journal of Proteome Research},
year = {2008},
volume = {7},
number = {7},
pages = {3022--3027}
}

@inproceedings{Amdahl:1967,
author = {Amdahl, Gene M.},
title = {{Validity of the single processor approach to achieving large scale computing capabilities}},
booktitle = {AFIPS `67: Proceedings of the Spring Joint Computer Conference},
year = {1967},
pages = {483--485},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Sweeney:2009,
author = {Sweeney, Tim},
title = {{The End of the GPU Roadmap}},
booktitle = {High Performance Graphics},
year = {2009},
month = aug,
annote = {Presentation. Mainstream GPUs emerged 12 years ago and rapid evolved from fixed-function graphics accelerators to semi-programmable computing devices. Argues that the GPU roadmap is now coming to an end, and that future PCs and game consoles will be powered by general computing devices, utilising multi-core vector-processing units to run all code, graphics and non-graphics, uniformly, at teraflop performance levels. Gives an overview of the design dimensions impacting such an architectures, such as caches, threads, vector sizes, and programming models. Speculates the rise of a new graphics pipeline based on REYES micropolygon rasterisation, software transactional memory, and purely functional shaders.}
}

@inproceedings{Svensson:2012ho,
author = {Svensson, Bo Joel and Sheeran, Mary},
title = {{Parallel programming in Haskell almost for free}},
booktitle = {the 1st ACM SIGPLAN workshop},
year = {2012},
pages = {3--14},
publisher = {ACM Press},
address = {New York, New York, USA}
}

@webpage{Ghuloum:2007a,
author = {Ghuloum, Anwar},
title = {{The Problem(s) with GPGPU}},
year = {2007},
month = oct,
url = {http://blogs.intel.com/research/2007/10/the_problem_with_gpgpu.php}
}

@phdthesis{Anderson:2008vz,
author = {Anderson, Owen C},
title = {{Compiler Optimizations for a Time-constrained Environment}},
school = {Macalester College},
year = {2008},
month = apr
}

@inproceedings{Rose:1987,
author = {Rose, J. and Steele Jr, Guy L},
title = {{C*: An extended C language for data parallel programming}},
booktitle = {Proceedings of the Second International Conference on Supercomputing},
year = {1987},
pages = {2--16}
}

@article{Rafler:2011ui,
author = {Rafler, Stephan},
title = {{Generalization of Conway's "Game of Life" to a continuous domain - SmoothLife}},
journal = {arXiv.org},
year = {2011},
eprint = {1111.1567v2},
eprinttype = {arxiv},
eprintclass = {nlin.CG},
month = nov
}

@article{Duke:2012df,
author = {Duke, David and Carr, Hamish and Knoll, Aaron and Schunck, Nicolas and Nam, Hai Ah and Staszczak, Andrzej},
title = {{Visualizing Nuclear Scission through a Multifield Extension of Topological Analysis}},
journal = {IEEE Transactions on Visualization and Computer Graphics},
year = {2012},
volume = {18},
number = {12},
pages = {2033--2040},
month = dec
}

@inproceedings{Takano:1995,
author = {Takano, Akihiko and Meijer, Erik},
title = {{Shortcut deforestation in calculational form}},
booktitle = {FPCA '95: Proceedings of the seventh international conference on Functional programming languages and computer architecture},
year = {1995},
publisher = { ACM  Request Permissions},
month = oct,
annote = {Automatic program transformations to remove unnecessary intermediate data structures (deforestation). States that the technique is applicable for any functional program in function composition style, for any algebraic data type. Seems to generalise the foldr/build rule and its dual, and can be extended to work on primitive recursion.}
}

@techreport{Allen:2005,
author = {Allen, Eric and Chase, David and Hallett, Joe and Luchangco, Victor and Maessen, Jan-Willem and Ryu, Sukyoung and Steele Jr, Guy L and Tobin-Hochstadt, Sam and Dias, Joao and Eastlund, Carl and Flood, Christine and Lev, Yossi and McCosh, Cheryl},
title = {{The Fortress language specification, v1.0$\beta$}},
year = {2005},
month = mar
}

@article{Owens:2007,
author = {Owens, John D and Luebke, David and Govindaraju, Naga and Harris, Mark and ger, Jens Kr u and Lefohn, Aaron E and Purcell, Timothy J},
title = {{A Survey of General-Purpose Computation on Graphics Hardware}},
journal = {Computer Graphics Forum},
year = {2007},
volume = {26},
number = {1},
pages = {80--113},
annote = {Updated version of the original 2005 survey by the same name.}
}

@techreport{Emoto:2012ur,
author = {Emoto, Kento and Matsuzaki, Kiminori},
title = {{An Automatic Fusion Mechanism for Variable-Length List Skeletons in SkeTo}},
year = {2012},
number = {METR 2013-04},
month = feb
}

@article{Hussong:2009,
author = {Hussong, Rene and Gregorius, Barbara and Tholey, Andreas and Hildebrandt, Andreas},
title = {{Highly accelerated feature detection in proteomics data sets using modern graphics processing units}},
journal = {Bioinfomatics},
year = {2009},
volume = {25},
number = {15},
pages = {1937--1943},
month = may
}

@inproceedings{Sengupta:2007tc,
author = {Sengupta, Shubhabrata and Harris, Mark and Zhang, Yao and Owens, John D},
title = {{Scan primitives for GPU computing}},
booktitle = {GH `07: Proceedings of the 22nd ACM SIGGRAPH/EUROGRAPHICS symposium on Graphics hardware},
year = {2007},
pages = {97--106},
publisher = {Eurographics Association},
address = {Aire-la-Ville, Switzerland, Switzerland},
annote = {Discusses the applicability of scan primitives for parallel devices, and contributes a segmented scan algorithm for GPUs. Provides several example applications. Encourages the development of program libraries of primitive operations for code reuse and factorisation. Will be useful for the methodology of implementing algorithms on the GPU.}
}

@article{Wysocki:2005,
author = {Wysocki, Vicki H and Resing, Katheryn A and Zhang, Qingfen and Cheng, Guilong},
title = {{Mass spectrometry of peptides and proteins}},
journal = {Methods},
year = {2005},
volume = {35},
number = {3},
pages = {211--222},
month = mar
}

@incollection{Burtscher:2011uy,
author = {Burtscher, Martin and Pingali, Keshav},
title = {{An efficient CUDA implementation of the tree-based Barnes Hut n-body algorithm}},
booktitle = {GPU Gems Emerald Edition},
year = {2011},
editor = {Hwu, Wen-mei W.},
publisher = {Elsevier Science Publishers B. V},
month = sep,
annote = {http://www.gpucomputing.net/?q=node/1314}
}

@inproceedings{Svensson:2008a,
author = {Svensson, Joen and Sheeran, Mary and Claessen, Koen},
title = {{Obsidian: A domain specific embedded language for parallel programming of graphics processors}},
booktitle = {Proceedings of the 20th International Symposium on the Implementation and Application of Functional Languages},
year = {2008}
}

@inproceedings{Lefohn:2005,
author = {Lefohn, Aaron E and Kniss, Joe M and Hansen, Charles D and Whitaker, Ross T},
title = {{A streaming narrow-band algorithm: interactive computation and visualization of level sets}},
booktitle = {SIGGRAPH '05: ACM SIGGRAPH 2005 Courses},
year = {2005},
pages = {243},
publisher = {ACM},
address = {New York, NY, USA}
}

@article{Styczynski:2008,
author = {Styczynski, Mark P and Jensen, Kyle L and Rigoutsos, Isidore and Stephanopoulos, Gregory},
title = {{BLOSUM62 miscalculations improve search performance}},
journal = {Nature Biotechnology},
year = {2008},
volume = {26},
number = {3},
pages = {274--275},
month = mar
}

@inproceedings{Han:2009,
author = {Han, Tianyi David and Abdelrahman, Tarek S.},
title = {{hiCUDA: a high--level directive--based language for GPU programming}},
booktitle = {GPGPU-2: Proceedings of 2nd Workshop on General Purpose Processing on Graphics Processing Units},
year = {2009},
pages = {52--61},
publisher = {ACM},
address = {New York, NY, USA},
annote = {A directives-based language that resembles OpenMP, designed specifically for CUDA programs. Kernels are automatically extracted from the sequential code (no need to write in separate functions), and allows the specification of shared {\&} global/constant memory access schemes (block and cyclic). Main differences to OpenMP: - the threading hierarchy supported by hiCUDA is more complicated than the flat threading hierarchy supported by OMP - The GPU memory hierarchy (and supported access) is more complicated than the shared memory model of OMP - OMP supports a more general execution model than the SPMD model supported by hi/CUDA, so many OMP directives are not supported Disadvantages: - By using annotations, thread and data decomposition seems to be statically bound, whereas a native CUDA program can specify these at runtime (although in practice this may be uncommon) - It is sometimes required to make structural changes to the sequential code before applying the directives. For example, privatisation of array variables, loop interchange and unrolling. Authors believe that these (coupled with a few other optimisations) could lead to an automatically parallelising compiler. In reality, this is several rather large steps away...}
}

@inproceedings{Purcell:2005,
author = {Purcell, Timothy J and Buck, Ian and Mark, William R. and Hanrahan, Pat},
title = {{Ray tracing on programmable graphics hardware}},
booktitle = {SIGGRAPH `05: ACM SIGGRAPH 2005 Courses},
year = {2005},
pages = {268},
publisher = {ACM},
address = {New York, NY, USA}
}

@phdthesis{Chamberlain:2001,
author = {Chamberlain, Bradford L},
title = {{The Design and Implementation of a Region--Based Parallel Programming Language}},
school = {Department of Computer Science and Engineering, University of Washington},
year = {2001},
month = nov
}

@inproceedings{Lee:2008,
author = {Lee, Seyong and Min, Seung-Jai and Eigenmann, Rudolf},
title = {{OpenMP to GPGPU: a compiler framework for automatic translation and optimization}},
booktitle = {PPoPP `09: Proceedings of the 14th ACM SIGPLAN symposium on Principles and practice of parallel programming},
year = {2008},
pages = {101--110},
publisher = {ACM},
address = {New York, NY, USA},
annote = {Language is a little sloppy and imprecise, for example, terms such as "shared memory" are used in multiple contexts without clear definition, and the language is described as a SIMD programming model -- internally, this is true, but the what the programmer sees is a SPMD model. The paper itself describes a source-to-source translation of OpenMP parallel constructs to CUDA kernels. This seems to be done fairly well in general. There is some effort spent discussing difficulties with kernel identification that seem a little redundant. Towards the end of this section it is mentioned off-hand that kernels might also be identified in a bottom-up fashion, but this is not explored. Describes and implement two techniques to improve global memory access coalescing, and demonstrate that these both work well. These are similar to transformations common in compilers for vector processors. No described use of GPU streaming multiprocessor shared memory, although it is mentioned in passing as a possible target for caching. Section 5, performance evaluation: "some advanced compiler optimisations [...] were applied manually", no details. Seems a rather large omission when providing performance metrics for an "automated" system. Also no comparison between hand-written CUDA code (with and/or without use of shared memory), or CPU-GPU transfer statistics.}
}

@article{McCool:2008,
author = {McCool, Michael D},
title = {{Scalable Programming Models for Massively Multicore Processors}},
journal = {Proceedings of the IEEE},
year = {2008},
volume = {96},
number = {5},
pages = {816--831},
month = may,
annote = {Survey paper that examines parallel programming/processing models (generally, task \{\&} data parallelism) with an eye to scalability. Examines different ways that these can be implemented, especially for data-parallelism (SIMD, SPMD, SWAR, vector, collective operations). Examines architectural features of processors, including multi-core/chip CPUs, but focusing mostly on more highly parallel architectures (Cell BE \{\&} GPU). Concludes with a survey of parallel programming languages.}
}

@inproceedings{Lesniak:2010,
author = {Lesniak, Michael},
title = {{PASTHA: Parallelizing stencil calculations in Haskell}},
booktitle = {DAMP `10: Proceedings of the 5th ACM SIGPLAN workshop on Declarative aspects of multicore programming},
year = {2010},
pages = {5--14},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Mainland:2010vj,
author = {Mainland, Geoffrey and Morrisett, Greg},
title = {{Nikola: Embedding Compiled GPU Functions in Haskell}},
booktitle = {Haskell `10: Proceedings of the 2010 ACM SIGPLAN Symposium on Haskell},
year = {2010},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Rubinsteyn:2012ve,
author = {Rubinsteyn, Alex and Hielscher, Eric and Weinman, Nathaniel and Shasha, Dennis},
title = {{Parakeet: a just-in-time parallel accelerator for python}},
booktitle = {HotPar'12: Proceedings of the 4th USENIX conference on Hot Topics in Parallelism},
year = {2012},
publisher = { USENIX Association},
month = jun
}

@inproceedings{Spetka:2008,
author = {Spetka, S. and Hadzimujic, H. and Peek, S. and Flynn, C.},
title = {{High Productivity Languages for Parallel Programming Compared to MPI}},
booktitle = {DoD HPCMP Users Group Conference},
year = {2008},
pages = {413--417},
month = jul,
annote = {Compares parallel computing languages in terms of developer productivity, but does not define their notion of productivity at all. Compared are the de-facto parallel programming library MPI, and two new languages under development, Chapel and X10, and so can not compare the languages in terms of performance either. Contribution...?}
}

@inproceedings{Lucas:2006,
author = {Lucas, Philipp and Fritz, Nicolas and Wilhelm, Reinhard},
title = {{The CGiS Compiler}},
booktitle = {Proceedings of the 15th International Conference on Compiler Construction},
year = {2006},
pages = {105--108},
publisher = {Springer-Verlag},
month = mar
}

@book{Cesarini:2009,
author = {Cesarini, Francesco and Thompson, Simon},
title = {{Erlang Programming: A concurrent approach to software development}},
publisher = {O'Reilly Media, Inc.},
year = {2009}
}

@article{Schrijvers:2008ir,
author = {Schrijvers, Tom and Peyton Jones, Simon and Chakravarty, Manuel M T and Sulzmann, Martin},
title = {{Type checking with open type functions}},
journal = {SIGPLAN Notices},
year = {2008},
volume = {43},
number = {9},
pages = {51--62}
}

@article{Blelloch:1996kg,
author = {Blelloch, Guy E.},
title = {{Programming Parallel Algorithms}},
journal = {Communications of the ACM},
year = {1996},
volume = {39},
number = {3},
pages = {85--97},
annote = {Describes NESL, a nested data parallel language for developing parallel algorithms based on the model of work and depth rather than the machine-based model of running time. Specifically designed to allow high-level descriptions of parallel algorithms while retaining a well-understood mapping onto a performance model. Provides expected-performance relations for work and depth to running time. Claims that current low-level language descriptions obscure the meaning of the algorithms. Very high-level description of nested-data parallelism, no implementation details. Provides several example algorithms with work/depth analysis.}
}

@article{Eng:1994,
author = {Eng, Jimmy K and McCormack, Ashley L and John R Yates, III},
title = {{An approach to correlate tandem mass spectral data of peptides with amino acid sequences in a protein database}},
journal = {Journal of the American Society for Mass Spectrometry},
year = {1994},
volume = {5},
number = {11},
pages = {976--989},
month = nov,
annote = {Generate a measure of similarity between a measured tandem-MS spectrum and a peptide sequence from a protein database by way of calculating the cross-correlation between the measured and (theoretical) peptide spectra. The cross-correlation analysis is computationally expensive, and so the list of candidates to test is pruned by a first metric. Also limited accuracy when searching for short peptide sequences(?) Speed addressed in the subsequent SEQUEST paper.}
}

@inproceedings{Luo:2008bs,
author = {Luo, Yuancheng and Duraiswami, Ramani},
title = {{Canny edge detection on NVIDIA CUDA}},
booktitle = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops)},
year = {2008},
pages = {1--8},
publisher = {IEEE}
}

@book{Blelloch:1990ts,
author = {Blelloch, Guy E.},
title = {{Vector Models for Data-Parallel Computing}},
publisher = {MIT Press},
year = {1990},
annote = {Seminal paper for nested data parallelism. In the context of parallel computing, there are two kinds of time complexity: step complexity and work complexity. Step complexity is the number of parallel operations required to complete a computation given an infinite number of processors. Work complexity is the total numbor of operations on all processors. Ideally, a parallel algorithm has the same work complexity as a serial algorithm, however this is not possible even in theory for some algorithms, even if the step complexity is lower. Some problems are considered intrinsically serial, such as depth-first tree labeling.}
}

@booklet{OpenMP:2008,
title = {{OpenMP Application Program Interface, v3.0}},
author = {{OpenMP Architecture Review Board}},
month = may,
year = {2008}
}

@book{HoTT:2013wt,
author = {{HoTT}},
title = {{Homotopy Type Theory: Univalent Foundations of Mathematics}},
publisher = {The Univalent Foundations Program Institute for Advanced Study},
year = {2013},
month = jun
}

@inproceedings{Jones:2008a,
author = {Jones, Simon Peyton and Singh, Satnam},
title = {{A Tutorial on Parallel and Concurrent Programming in Haskell}},
booktitle = {Advanced Functional Programming Summer School 2008},
year = {2008},
publisher = {Springer-Verlag},
address = {Nijmegen, Holland},
month = may,
annote = {Broad-scope tutorial for the types of parallelism available in Haskell, including semi-implicit (par), explicit threads, transactional memory, and NDP. May be useful background to quickly get up to speed once implementation work begins.}
}

@article{Aebersold:2003,
author = {Aebersold, Ruedi and Mann, Matthias},
title = {{Mass spectrometry-based proteomics}},
journal = {Nature},
year = {2003},
volume = {422},
number = {6928},
pages = {198--207},
month = mar,
annote = {Describes the role and procedure of mass spectrometry-based proteomics as a tool for molecular and cellular biology. Compares commonly used methods/systems and their relative strengths and weaknesses.}
}

@book{Anonymous:2005vl,
title = {{link.springer.com}},
publisher = {Springer Berlin Heidelberg},
year = {2005},
address = {Berlin, Heidelberg}
}

@article{Blelloch:1993ts,
author = {Blelloch, Guy E. and Heroux, Michael A. and Zagha, Marco},
title = {{Segmented operations for sparse matrix computation on vector multiprocessors}},
year = {1993}
}

@inproceedings{Chakravarty:2007tc,
author = {Chakravarty, Manuel M T and Leshchinskiy, Roman and Jones, Simon Peyton and Keller, Gabriele and Marlow, Simon},
title = {{Data Parallel Haskell: A status report}},
booktitle = {Declarative Aspects of Multicore Programming},
year = {2007},
publisher = {ACM},
month = nov,
annote = {Similar to Jones:2008, draws together the work of many previous papers. Covers topics in more detail, instead of providing a large running example/motivation, and includes a discussion of stream fusion, omitted from the later work. Aims to describe the language and implementation of nested data parallelism in Haskell, with a broad high-level scope. Doesn't really discuss limitations of the system, as the goal is to present the current state of the implementation -- algorithm discussions can be found in the more detailed papers upon which the system is based.}
}

@inproceedings{Chakravarty:2001gz,
author = {Chakravarty, Manuel M T and Keller, Gabriele and Leshtchinsky, Roman and Pfannenstiel, Wolf},
title = {{Nepal -- Nested Data Parallelism in Haskell}},
booktitle = {Euro-Par 2001: Parallel Processing},
year = {2001},
editor = {Sakellariou, Rizos and Keane, John and Gurd, John R and Freeman, Len},
pages = {524--534},
publisher = {Springer-Verlag},
annote = {Discusses a possible implementation of nested data-parallelism in Haskell (as an extension). Data parallelism restricts parallelism to the application of a single function to all elements of a collective structure. The authors argue that compared to control parallelism, this allows the programmer and compiler to better predict the parallel behaviour of a program, which ultimately allows for finer parallel granularity and allows for more radical compiler optimisations. The programming model is also closer to sequential programming, and arguably easier to understand. Extends NESL (Blelloch et. al.) to support user-defined recursive and sum types, and also benefits from other features of Haskell (I/O, type system, standardised language, etc...) Parallel and sequential structures are distinguished through the type system.}
}

@inproceedings{Satish:2009kx,
author = {Satish, Nadathur and Harris, Mark and Garland, Michael},
title = {{Designing efficient sorting algorithms for manycore GPUs}},
booktitle = {IPDPS '09: Proceedings of the 2009 IEEE International Symposium on Parallel{\&}Distributed Processing},
year = {2009},
pages = {1--10},
publisher = { IEEE Computer Society},
month = may
}

@inproceedings{Harris:2007te,
author = {Harris, Mark},
title = {{Optimizing Parallel Reduction in CUDA}},
booktitle = {CUDA SDK},
year = {2007}
}

@inproceedings{Gill:2009dx,
author = {Gill, Andy},
title = {{Type-Safe Observable Sharing in Haskell}},
booktitle = {Proceedings of the 2009 ACM SIGPLAN Haskell Symposium},
year = {2009},
pages = {117--128},
month = sep
}

@book{OpenCL:2009,
editor = {Munshi, Aaftab},
title = {{The OpenCL Specification, v1.0}},
publisher = {Khronos OpenCL Working Group},
year = {2009},
month = may
}

@article{Feo:1988,
author = {Feo, John T},
title = {{An analysis of the computational and parallel complexity of the Livermore Loops}},
journal = {Parallel Computing},
year = {1988},
volume = {7},
number = {2},
pages = {163--185}
}

@article{Tarditi:2006,
author = {Tarditi, David and Puri, Sidd and Oglesby, Jose},
title = {{Accelerator: using data parallelism to program GPUs for general-purpose uses}},
journal = {SIGOPS Operating Systems Review},
year = {2006},
volume = {40},
number = {5},
pages = {325--335},
annote = {A C\{\#} library of abstractions for data-parallel arrays and operations that allows programmers to combine operations for the CPU and GPU within a single application. To improve efficiency, the library uses a graph-based lazy evaluation strategy of data-parallel operations on the GPU. Evaluation is typically triggered by the explicit conversion of an array from a data-parallel to a serial representation.}
}

@inproceedings{Lippmeier:WZGJsUgV,
author = {Lippmeier, Ben and Chakravarty, Manuel M T and Keller, Gabriele and Robinson, Amos},
title = {{Data Flow Fusion with Series Expressions in Haskell}},
booktitle = {Haskell '13: Proceedings of the 2013 symposium on Haskell}
}

@book{Gibbons:1988,
author = {Gibbons, Alan and Rytter, Wojciech},
title = {{Efficient parallel algorithms}},
publisher = {Cambridge University Press},
year = {1988}
}

@inproceedings{Owens:2005,
author = {Owens, John D and Luebke, David and Govindaraju, Naga and Harris, Mark and Kr{\"u}ger, Jens and Lefohn, Aaron E and Purcell, Timothy J},
title = {{A Survey of General-Purpose Computation on Graphics Hardware}},
booktitle = {Eurographics 2005: State of the Art Reports},
year = {2005},
pages = {21--51},
month = aug,
annote = {Comprehensive survey paper of the (then) current features and limitations of graphics hardware in the context of their use for general purpose computation. Discussion of the differences between CPU and GPU hardware and software programming models, and methods to improve flow control. Includes many examples of algorithms and applications which are well categorised, with evolution of algorithms/methods as additional programmability was introduced. GPGPU techniques discussed include: * stream operations (map, reduce, scatter/gather, sort, search, filter) * data structures (dense/sparse, static/dynamic) * Differential equations and linear algebra}
}

@article{Nickolls:2008io,
author = {Nickolls, John and Buck, Ian and Garland, Michael and Skadron, Kevin},
title = {{Scalable parallel programming with CUDA}},
journal = {Queue},
year = {2008},
volume = {6},
number = {2},
pages = {40},
month = mar
}

@article{Huet:1997ue,
author = {Huet, Gerard},
title = {{Functional Pearl: The Zipper}},
journal = {Journal of Functional Programming},
year = {1997},
volume = {7},
number = {5},
pages = {549--554},
month = sep
}

@article{Wall:1991,
author = {Wall, David W.},
title = {{Limits of instruction-level parallelism}},
journal = {SIGPLAN Notices},
year = {1991},
volume = {26},
number = {4},
pages = {176--188}
}

@article{Buck:2004,
author = {Buck, Ian and Foley, Tim and Horn, Daniel and Sugerman, Jeremy and Fatahalian, Kayvon and Houston, Mike and Hanrahan, Pat},
title = {{Brook for GPUs: Stream Computing on Graphics Hardware}},
journal = {ACM Transactions on Graphics},
year = {2004},
volume = {23},
number = {3},
pages = {777--786},
annote = {General purpose language for GPUs based on C (pre-cuda), which supports the definition of functions that are compiled for GPU execution and invoked in multiple data-parallel instances from CPU code. Functions can not have global side-effects and are restricted to meet the constraints of the GPU hardware. As the GPU code must be in a separate function, program decomposition is partially constrained by hardware considerations. Historically significant. There might not be a lot of influence to my work, although there seem to be some interesting methods for packing data and splitting large kernels. Also good performance modeling.}
}

@inproceedings{Iverson:1962,
author = {Iverson, Kenneth E.},
title = {{A programming language}},
booktitle = {AIEE-IRE `62: Proceedings of the Spring Joint Computer Conference},
year = {1962},
pages = {345--351},
publisher = {ACM},
address = {New York, NY, USA},
month = may
}

@inproceedings{Stam:1999ey,
author = {Stam, Jos},
title = {{Stable fluids}},
booktitle = {SIGGRAPH '99: Proceedings of the 26th annual conference on Computer graphics and interactive techniques},
year = {1999},
publisher = { ACM Press/Addison-Wesley Publishing Co.  Request Permissions},
month = jul
}

@inproceedings{Sulzmann:2007ch,
author = {Sulzmann, Martin and Chakravarty, Manuel M T and Jones, Simon Peyton and Donnelly, Kevin},
title = {{System F with type equality coercions}},
booktitle = {TLDI `07: Proceedings of the Second ACM SIGPLAN Workshop on Types in Language Design and Implementation},
year = {2007},
pages = {53--66},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Ma:2010ft,
author = {Ma, Wenjing and Agrawal, Gagan},
title = {{An integer programming framework for optimizing shared memory use on GPUs}},
booktitle = {2010 International Conference on High Performance Computing (HiPC)},
year = {2010},
pages = {1--10},
publisher = {IEEE},
month = dec
}

@inproceedings{Keller:1998fx,
author = {Keller, Gabriele and Chakravarty, Manuel M T},
title = {{Flattening Trees}},
booktitle = {Euro-Par 1998: Parallel Processing},
year = {1998},
editor = {Pritchard, David and Reeve, Jeff},
pages = {709--719},
publisher = {Springer-Verlag},
annote = {Extend the flattening transform of Blelloch and Sabot to support user-defined recursive data types, which allows parallel tree structures to be defined. Previously, tree structures were mapped to vectors, requiring explicit index calculations to track parent-child relationships, and leading to suboptimal data distributions on distributed-memory machines.}
}

@techreport{Nikhil:1993,
author = {Nikhil, Rishiyur S},
title = {{An Overview of the Parallel Language Id (a foundation for pH, a parallel dialect of Haskell)}},
year = {1993},
address = {Cambridge Research Laboratory}
}

@article{Claessen:2002,
author = {Claessen, Koen and Hughes, John},
title = {{Testing monadic code with QuickCheck}},
journal = {SIGPLAN Notices},
year = {2002},
volume = {37},
number = {12},
pages = {47--59}
}

@inproceedings{Fatahalian:2004,
author = {Fatahalian, K. and Sugerman, J. and Hanrahan, P.},
title = {{Understanding the efficiency of GPU algorithms for matrix-matrix multiplication}},
booktitle = {HWWS `04: Proceedings of the ACM SIGGRAPH/EUROGRAPHICS conference on Graphics hardware},
year = {2004},
pages = {133--137},
publisher = {ACM},
address = {New York, NY, USA},
annote = {Present an analysis of dense matrix-matrix multiplication, and find that even though the algorithm has regular data access patterns and highly parallel computational requirements, the lack of high bandwidth access to cached data will impair performance and limit the types of applications that will benefit from the computational power available from these architectures.}
}

@techreport{Blelloch:1995ut,
author = {Blelloch, Guy E.},
title = {{NESL: A Nested Data-Parallel Language}},
year = {1995},
number = {CMU-CS-95-170},
month = sep
}

@techreport{Bonachea:2006,
author = {Hilfinger, Paul N. and Bonachea, Dan and Datta, Kaushik and Gay, David and Graham, Susan and Kamil, Amir and Liblit, Ben and Pike, Geoff and Su, Jimmy and Yelick, Katherine},
title = {{Titanium Language Reference Manual, v2.20}},
year = {2006},
month = aug
}

@techreport{Ghuloum:2007,
author = {Ghuloum, Anwar and Sprangle, Eric and Fang, Jesse},
title = {{Flexible Parallel Programming for Terascale Architectures with Ct}},
year = {2007},
month = apr,
annote = {Data-parallel programming platform under development by Intel that targets x86 multicore CPUs. Supports the SPMD stream programming model and uses an embedded C++ interface. Includes an implementation of segmented collectives, which are especially useful for algorithms using nested data parallelism.}
}

@webpage{Kanter:2008,
author = {Kanter, David},
title = {{NVIDIA's GT200: Inside a Parallel Processor}},
year = {2008},
month = aug,
url = {http://www.realworldtech.com/page.cfm?ArticleID=RWT090808195242}
}

@manual{NVIDIA:2012vj,
title = {{Parallel Thread Execution ISA}},
author = {{NVIDIA}},
edition = {3.1},
month = sep,
year = {2012}
}

@inproceedings{Coutts:2007ia,
author = {Coutts, Duncan and Stewart, Don and Leshchinskiy, Roman},
title = {{Rewriting Haskell strings}},
booktitle = {Practical Aspects of Declarative Languages 8th International Symposium (PADL 2007)},
year = {2007},
pages = {50--64},
publisher = {Springer-Verlag}
}

@techreport{NVIDIA:2012wf,
author = {{NVIDIA}},
title = {{CUDA C Programming Guide}},
year = {2012},
number = {PG-02829-001\_v5.0},
month = oct
}

@inproceedings{Seiler:2008,
author = {Seiler, Larry and Carmean, Doug and Sprangle, Eric and Forsyth, Tom and Abrash, Michael and Dubey, Pradeep and Junkins, Stephen and Lake, Adam and Sugerman, Jeremy and Cavin, Robert and Espasa, Roger and Grochowski, Ed and Juan, Toni and Hanrahan, Pat},
title = {{Larrabee: a many-core x86 architecture for visual computing}},
booktitle = {SIGGRAPH `08: ACM SIGGRAPH 2008 papers},
year = {2008},
pages = {1--15},
publisher = {ACM},
address = {New York, NY, USA}
}

@incollection{McBride:2005jv,
author = {McBride, Conor},
title = {{Epigram: Practical Programming with Dependent Types}},
booktitle = {Lecture Notes in Computer Science},
year = {2005},
pages = {130--170},
publisher = {Springer Berlin Heidelberg},
address = {Berlin, Heidelberg}
}

@book{Koelbel:1994,
author = {Koelbel, Charles H. and Loveman, David B. and Schreiber, Robert S. and Steele Jr, Guy L and Zosel, Mary E.},
title = {{The high performance Fortran handbook}},
publisher = {MIT Press},
year = {1994},
address = {Cambridge, MA, USA}
}

@book{PeytonJones:2000ks,
author = {Peyton Jones, Simon and Marlow, Simon and Elliott, Conal},
editor = {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan and Koopman, Pieter and Clack, Chris},
title = {{Stretching the Storage Manager: Weak Pointers and Stable Names in Haskell}},
publisher = {Springer Berlin Heidelberg},
year = {2000},
volume = {1868},
address = {Berlin, Heidelberg}
}

@article{Valiant:1990,
author = {Valiant, Leslie G.},
title = {{A bridging model for parallel computation}},
journal = {Communications of the ACM},
year = {1990},
volume = {33},
number = {8},
pages = {103--111},
annote = {Describes bulk-synchronous task parallelism model. This is similar to the SPMD model, and is (similarly) strictly more powerful than the SIMD model.}
}

@inproceedings{Bell:2009,
author = {Bell, Nathan and Garland, Michael},
title = {{Implementing sparse matrix-vector multiplication on throughput-oriented processors}},
booktitle = {Supercomputing `09: Proceedings of the 2009 Conference on High Performance Computing Networking, Storage and Analysis},
year = {2009},
pages = {1--11},
publisher = {ACM},
address = {New York, NY, USA}
}

@techreport{HLSL:2009,
author = {{Microsoft Corporation}},
title = {{DirectX High--Level Shading Language, v10}},
year = {2009}
}

@inproceedings{Charles:2005,
author = {Charles, Philippe and Grothoff, Christian and Saraswat, Vijay and Donawa, Christopher and Kielstra, Allan and Ebcioglu, Kemal and von Praun, Christoph and Sarkar, Vivek},
title = {{X10: an object-oriented approach to non-uniform cluster computing}},
booktitle = {Proceedings of the 20th annual ACM SIGPLAN International Conference on Object--Oriented Systems, Languages and Applications},
year = {2005},
pages = {519--538},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Zhang:2010jc,
author = {Zhang, Eddy Z and Jiang, Yunlian and Guo, Ziyu and Shen, Xipeng},
title = {{Streamlining GPU applications on the fly}},
booktitle = {the 24th ACM International Conference},
year = {2010},
pages = {115--126},
publisher = {ACM Press},
address = {New York, New York, USA}
}

@article{Dean:2008,
author = {Dean, Jeffrey and Ghemawat, Sanjay},
title = {{MapReduce: simplified data processing on large clusters}},
journal = {Communications of the ACM},
year = {2008},
volume = {51},
number = {1},
pages = {107--113}
}

@article{Chakravarty:2001dt,
author = {Chakravarty, Manuel M T and Keller, Gabriele},
title = {{Functional array fusion}},
journal = {SIGPLAN Notices},
year = {2001},
volume = {36},
number = {10},
pages = {205--216}
}

@inproceedings{Keller:1999ic,
author = {Keller, Gabriele and Chakravarty, Manuel M T},
title = {{On the Distributed Implementation of Aggregate Data Structures by Program Transformation}},
booktitle = {Parallel and Distributed Processing, Fourth International Workshop on High-Level Parallel Programming Models and Supportive Environments (HIPS `99)},
year = {1999},
editor = {Rolim, Jos e},
pages = {108--122},
publisher = {Springer-Verlag},
annote = {A central component of data-parallel languages are operations that manipulate collections of data (arrays, vectors, lists, sets...) as a whole. This is commonly implemented through a library of routines encapsulating machine-dependent code. This work proposes to break the library view into a set of local computations and global communication operations. These operations are visible to the compiler, which can then apply automatic transformation rules to minimise communication and make better use of the memory hierarchy. The contribution is to enable the automatic use of these optimisations for the parallel implementation of aggregrate structures in collection-oriented languages (the optimisations themselves are not new). Achieved through an intermediate language, where local and distributed types are distinguished through the type system.}
}

@book{Hinze:2002dv,
author = {Hinze, Ralf and Jeuring, Johan and L{\"o}h, Andres},
editor = {Boiten, Eerke A and M{\"o}ller, Bernhard},
title = {{Type-Index Data Types}},
publisher = {Springer Berlin Heidelberg},
year = {2002},
volume = {2386},
series = {Lecture Notes in Computer Science},
address = {Berlin, Heidelberg},
month = jun
}

@inproceedings{Mark:2003,
author = {Mark, William R. and Glanville, R. Steven and Akeley, Kurt and Kilgard, Mark J.},
title = {{Cg: a system for programming graphics hardware in a C-like language}},
booktitle = {SIGGRAPH `03: ACM SIGGRAPH 2003 Papers},
year = {2003},
pages = {896--907},
publisher = {ACM},
address = {New York, NY, USA}
}

@inproceedings{Axelsson:2012es,
author = {Axelsson, Emil},
title = {{A generic abstract syntax model for embedded languages}},
booktitle = {ICFP '12: Proceedings of the 17th ACM SIGPLAN international conference on Functional programming},
year = {2012},
pages = {323--334},
publisher = {ACM},
month = oct
}

@book{Skillicorn:2005,
author = {Skillicorn, David},
title = {{Foundations of Parallel Programming (Cambridge International Series on Parallel Computation)}},
publisher = {Cambridge University Press},
year = {2005},
address = {New York, NY, USA}
}

@inproceedings{Baghsorkhi:2009,
author = {Baghsorkhi, Sara S. and Hwu, Wen-mei W.},
title = {{Analytical Performance Prediction for Evaluation and Tuning of GPGPU Applications}},
booktitle = {Workshop on Exploiting Parallelism using GPUs and other Hardware-Assisted Methods (EPHAM 2009)},
year = {2009},
annote = {Presents a static, analytical performance model for GPUs, capturing full system complexity and demonstrating high accuracy in predicting the performance trend of implementations. In cases where it cannot determine the precise performance for a kernel, it provides lower and upper bounds. Intended to be used as part of an automatically optimising compiler, to model performance and prune the search space for kernel optimisations. Not directly related to my work, but could be of interesting use (as a toolkit).}
}

@article{Canny:1986et,
author = {Canny, John F},
title = {{A Computational Approach to Edge Detection}},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
year = {1986},
number = {6},
pages = {679--698}
}

@techreport{CUDA:2008,
author = {{NVIDIA}},
title = {{CUDA: Compute Unified Device Architecture, v2.0}},
year = {2008}
}

@article{Blelloch:1994vc,
author = {Blelloch, Guy E. and Chatterjee, Siddhartha and Hardwick, Jonathan C and Sipelstein, Jay and Zagha, Marco},
title = {{Implementation of a Portable Nested Data-Parallel Language}},
journal = {Journal of Parallel and Distributed Computing},
year = {1994},
volume = {21},
number = {1},
pages = {4--14},
annote = {Implementation details of the NESL nested data-parallel language. c.f. Blelloch:1996 Performance comparison for a number of different hardware architectures. Achieves aim of concise description of parallel algorithms, relies on automatically flattening nested data. Demonstrates good performance and concise description for irregular data structures (a specific aim), although somewhat irrelevant now due to changing hardware (no vector/super computer architectures in large use anymore, no limitations for dynamic memory management as in F77).}
}

@booklet{Blelloch:1990a,
title = {{Vector Models for Data-Parallel Computing}},
year = {1990},
annote = {Seminal paper for nested data parallelism. In the context of parallel computing, there are two kinds of time complexity: step complexity and work complexity. Step complexity is the number of parallel operations required to complete a computation given an infinite number of processors. Work complexity is the total numbor of operations on all processors. Ideally, a parallel algorithm has the same work complexity as a serial algorithm, however this is not possible even in theory for some algorithms, even if the step complexity is lower. Some problems are considered intrinsically serial, such as depth-first tree labeling.}
}

@article{Esmaeilzadeh:2013bw,
author = {Esmaeilzadeh, Hadi and Blem, Emily and Amant, Ren{\'e}e St and Sankaralingam, Karthikeyan and Burger, Doug},
title = {{Power challenges may end the multicore era}},
journal = {Communications of the ACM},
year = {2013},
volume = {56},
number = {2},
pages = {93},
month = feb
}

@article{Blelloch:1989fp,
author = {Blelloch, Guy E.},
title = {{Scans as primitive parallel operations}},
journal = {IEEE Transactions on Computers},
year = {1989},
volume = {38},
number = {11},
pages = {1526--1538}
}

@article{Filipovic:_b2q1-zX,
author = {Filipovic, Jir{\'\i} and Madzin, Mat{\'u}s and Fousek, Jan and Matyska, Ludek},
title = {{Optimizing CUDA Code By Kernel Fusion---Application on BLAS}},
journal = {arXiv.org},
year = {2013},
eprint = {1305.1183v1},
eprinttype = {arxiv},
eprintclass = {cs.DC},
month = may
}

@inproceedings{McDonell:2013wi,
author = {McDonell, Trevor L. and Chakravarty, Manuel M T and Keller, Gabriele and Lippmeier, Ben},
title = {{Optimising Purely Functional GPU Programs}},
booktitle = {ICFP '13: Proceedings of the 18th ACM SIGPLAN international conference on Functional programming},
year = {2013},
month = sep
}

@article{Klockner:2012tj,
author = {Kl{\"o}ckner, Andreas and Pinto, Nicolas and Lee, Yunsup and Catanzaro, Bryan and Ivanov, Paul and Fasih, Ahmed},
title = {{PyCUDA and PyOpenCL: A scripting-based approach to GPU run-time code generation}},
journal = {Parallel Computing},
year = {2012},
volume = {38},
number = {3},
month = mar
}

@book{Kirk:2010we,
author = {Kirk, David and Hwu, Wen-mei W.},
title = {{Programming Massively Parallel Processors}},
publisher = {Springer},
year = {2010},
edition = {1st Edition.},
month = oct
}

@inproceedings{Warren:1984ka,
author = {Warren, Joe},
title = {{A hierarchical basis for reordering transformations}},
booktitle = {the 11th ACM SIGACT-SIGPLAN symposium},
year = {1984},
pages = {272--282},
publisher = {ACM Press},
address = {New York, New York, USA}
}

@inproceedings{Claessen:2012hl,
author = {Claessen, Koen and Sheeran, Mary and Svensson, Bo Joel},
title = {{Expressive Array Constructs in an Embedded GPU Kernel Programming Language}},
booktitle = {DAMP '12},
year = {2012},
pages = {21},
publisher = {ACM Press},
address = {New York, New York, USA}
}

@inproceedings{Catanzaro:2011cn,
author = {Catanzaro, Bryan and Garland, Michael and Keutzer, Kurt},
title = {{Copperhead: Compiling an embedded data parallel language}},
booktitle = {PPoPP '11: Proceedings of the 16th ACM symposium on Principles and practice of parallel programming},
year = {2011},
publisher = { ACM  Request Permissions},
month = feb
}

@article{2012JCoPh.231.2825B,
author = {B{\'e}dorf, Jeroen and Gaburov, Evghenii and Portegies Zwart, Simon},
title = {{A sparse octree gravitational N-body code that runs entirely on the GPU processor}},
journal = {Journal of Computational Physics},
year = {2012},
volume = {231},
number = {7},
pages = {2825--2839},
month = apr
}

@article{Jones:2012we,
author = {Jones, Will and Field, Tony and Allwood, Tristan},
title = {{Deconstraining DSLs}},
journal = {ICFP '12: Proceedings of the 17th ACM SIGPLAN international conference on Functional programming},
year = {2012}
}

@inproceedings{Hinze:2010ub,
author = {Hinze, Ralf},
title = {{Type fusion}},
booktitle = {AMAST'10: Proceedings of the 13th international conference on Algebraic methodology and software technology},
year = {2010},
pages = {92--110},
publisher = { Springer-Verlag},
month = jun
}

@inproceedings{Sewell:2007jw,
author = {Sewell, Peter and Nardelli, Francesco Zappa and Owens, Scott and Peskine, Gilles and Ridge, Thomas and Sarkar, Susmit and Strni{\v s}a, Rok},
title = {{Ott: effective tool support for the working semanticist}},
booktitle = {ICFP '07: Proceedings of the 12th ACM SIGPLAN international conference on Functional programming},
year = {2007},
publisher = { ACM  Request Permissions},
month = oct
}

@inproceedings{Yorgey:2012fs,
author = {Yorgey, Brent A and Weirich, Stephanie and Cretin, Julien and Jones, Simon Peyton and Vytiniotis, Dimitrios and Magalh{\~a}es, Jos{\'e} Pedro},
title = {{Giving Haskell a promotion}},
booktitle = {TLDI '12: Proceedings of the 8th ACM SIGPLAN workshop on Types in language design and implementation},
year = {2012},
publisher = { ACM  Request Permissions},
month = jan
}

@inproceedings{Sarkar:1991ff,
author = {Sarkar, Vivek and Gao, Guang R},
title = {{Optimization of array accesses by collective loop transformations}},
booktitle = {the 5th international conference},
year = {1991},
pages = {194--205},
publisher = {ACM Press},
address = {New York, New York, USA}
}

@article{Sewell:2010ds,
author = {Sewell, Peter and Nardelli, Francesco Zappa and Owens, Scott and Peskine, Gilles and Ridge, Thomas and Sarkar, Susmit and Strni{\v s}a, Rok},
title = {{Ott: Effective tool support for the working semanticist}},
journal = {Journal of Functional Programming},
year = {2010},
volume = {20},
number = {01},
pages = {71},
month = jan
}

@book{Hinze:2012ee,
author = {Hinze, Ralf},
title = {{Kan Extensions for Program Optimisation \emph{Or:} Art and Dan explain an Old Trick}},
publisher = {Springer Berlin Heidelberg},
year = {2012},
volume = {7342},
series = {Mathematics of Program Construction},
address = {Berlin, Heidelberg}
}

@article{Petsko:2007kg,
author = {Petsko, Gregory A},
title = {{A day in the life of a genome biologist in the not-too-distant future}},
journal = {Genome Biology},
year = {2007},
volume = {8},
number = {3},
pages = {104},
annote = {Indeed not-to-distant future: 
"6:15 pm to 7 pm.packed up to go home. Waited 45 minutes for shuttle bus to parking lot. while waiting, checked latest news on iPhone."}
}

@article{Wadler:1990ix,
author = {Wadler, Philip},
title = {{Deforestation: Transforming programs to eliminate trees}},
journal = {Theoretical Computer Science},
year = {1990},
volume = {73},
number = {2},
pages = {231--248},
month = jun
}

@article{Eddy:2005cj,
author = {Eddy, Sean R},
title = {{``Antedisciplinary'' Science}},
journal = {PLoS Computational Biology},
year = {2005},
volume = {1},
number = {1},
pages = {e6}
}

@article{Walbot:2009ek,
author = {Walbot, Virginia},
title = {{Are we training pit bulls to review our manuscripts?}},
journal = {Journal of Biology},
year = {2009},
volume = {8},
number = {3},
pages = {24}
}

@article{Milloy:2012ev,
author = {Milloy, J A and Faherty, B K and Gerber, S A},
title = {{Tempest: GPU-CPU Computing for High-Throughput Database Spectral Matching}},
journal = {Journal of Proteome Research},
year = {2012},
volume = {11},
number = {7},
pages = {3581--3591}
}

@proceedings{Brown:5MPT6ozW,
title = {{Delite}}
}

@article{Svensson:2012tl,
author = {Svensson, Joel Bo and Newton, Ryan},
title = {{Parallel programming in Haskell almost for free: an embedding of intel's array building blocks}},
journal = {Proceedings of the 1st ACM SIGPLAN workshop on Functional high-performance computing},
year = {2012},
pages = {3--14}
}

@article{Svenningsson:2002ws,
author = {Svenningsson, Josef},
title = {{Shortcut fusion for accumulating parameters {\&} zip-like functions}},
journal = {ICFP '02: Proceedings of the seventh ACM SIGPLAN international conference on Functional programming},
year = {2002}
}

@article{Ohori:2007ug,
author = {Ohori, Atsushi and Sasano, Isao},
title = {{Lightweight fusion by fixed point promotion}},
journal = {POPL '07: Proceedings of the 34th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
year = {2007}
}

@article{Ghani:2005vz,
author = {Ghani, Neil and Johann, Patricia and Uustalu, Tarmo and Vene, Varmo},
title = {{Monadic augment and generalised short cut fusion}},
journal = {ICFP '05: Proceedings of the tenth ACM SIGPLAN international conference on Functional programming},
year = {2005}
}

@inproceedings{Harper:2012vb,
author = {Harper, Thomas},
title = {{A library writer's guide to shortcut fusion}},
booktitle = {Haskell '11: Proceedings of the 4th ACM symposium on Haskell},
year = {2012},
publisher = { ACM  Request Permissions},
month = jan
}

@article{Launchbury:2000vu,
author = {Launchbury, John and 'c, Sava Krsti and Sauerwein, Timothy E},
title = {{Zip fusion with hyperfunctions}},
year = {2000}
}

@article{PeytonJones:2003gb,
author = {Peyton Jones, Simon and Marlow, Simon},
title = {{Secrets of the Glasgow Haskell Compiler inliner}},
journal = {Journal of Functional Programming},
year = {2003},
volume = {12},
number = {4-5},
pages = {393--434},
month = jul
}

@inproceedings{Alpern:1988hw,
author = {Alpern, Bowen and Wegman, Mark N. and Zadeck, F. Kenneth},
title = {{Detecting Equality of Variables in Programs}},
booktitle = {POPL `88: Proceedings of the 15th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
year = {1988},
pages = {1--11},
publisher = {ACM Press},
address = {New York, New York, USA}
}

